{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn-aMcsrJAl6"
   },
   "source": [
    "##랭체인을 이용한 GPT-4호출하기\n",
    "랭체인을 이용해서 GPT-4를 호출하는 방법과 이전 대화를 기억하는 방법에 대해 다룹니다.이제 필요한 랭체인 도구들을 임포트 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15005,
     "status": "ok",
     "timestamp": 1753523535624,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "HiatD6yLI_V1",
    "outputId": "65b48580-f8f5-4f53-f150-b576c22ccd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.71)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_openai, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain_community-0.3.27 langchain_openai-0.3.28 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoyW4dQwJWgh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.tracers.stdout import ConsoleCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRUQ79wVKEsu"
   },
   "source": [
    "다음으로 os.environ['OPENAI_API_KEY']에 발급받은 OpenAI API 키 값을 입력합니다. 해당 코\n",
    "드는 현재 실습 환경에 OpenAI API 키 값을 세팅한다는 의미입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMJQycMqJ_Y1"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"Openai_api_key\"\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,   # 창의성 (0.0~2.0)\n",
    "    max_tokens=2048,\n",
    "    model_name = \"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nE6LZJPKp9n"
   },
   "source": [
    "랭체인 패키지를 통해서도 오픈 AI 의 GPT‐4 API 를 사용할 수 있는데, openai 패키지를 통해 GPT‐4 API 를 사용하는 방법과 랭체인 패키지를 통해 GPT‐4 API 를 사용하는 방법은 다릅니다. 랭체인 패키지를 사용해 GPT‐4 를 사용하기 위해서는 ChatOpenAI()를 이용하여 llm 객체를 생성해야 합니다. 이때 openai 패키지로 GPT‐4 API 를 사용할 때와 마찬가지로 ChatOpenAI() 내부에 다양한 설정값들을 세팅할 수 있습니다.\n",
    "\n",
    "예를 들어, temperature는 GPT‐4 에게 무작위성 또는 창의성을 주는 파라미터로서 0~2 사이의 값을\n",
    "가지며, 0 에 가까울수록 LLM 은 사실적인 답변을 내놓고, 2 에 가까울수록 의외의 답변을 내놓습니다. max_tokens는 GPT‐4 의 답변의 길이를 조절하는 값이며, model_name은 다양한 GPT‐4 모델 중 사용하고자 하는 모델의 이름을 설정하는 곳입니다. 이 파라미터들은 랭체인이 아니라 openai 패키지를 통해 GPT‐4 를 사용할 때도 사용할 수 있는 동일한 파라미터들입니다.\n",
    "\n",
    "이렇게 선언된 llm 객체는 invoke()를 통해 사용자의 질문을 전달하고 답변을 얻을 수 있습니다. 다음 코드에서는 \"세종대왕이 누구인지 설명해주세요\"라는 질문을 던지고 답변을 출력합니다. invoke()를 통해 얻은 답변을 result에 저장하고, 답변을 출력하기 위해서는 .content를 result 뒤에 붙여서 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3342,
     "status": "ok",
     "timestamp": 1753524067592,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "RRmaoKkjLBk_",
    "outputId": "53fc439f-3087-485d-9b0c-5ff726b9b7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세종대왕은 조선의 제4대 왕으로, 한국 역사에서 가장 존경받는 군주 중 한 명입니다. 그는 1397년에 태어나 1418년부터 1450년까지 재위하였습니다. 세종대왕은 여러 방면에서 뛰어난 업적을 남겼는데, 그 중 가장 유명한 것은 한글의 창제입니다. 한글은 백성들이 쉽게 읽고 쓸 수 있도록 고안된 문자 체계로, 1443년에 창제되어 1446년에 반포되었습니다.\n",
      "\n",
      "세종대왕은 또한 과학, 기술, 문화, 경제 등 다양한 분야에서 발전을 이끌었습니다. 그는 천문학, 의학, 농업 등 여러 분야의 연구를 장려하고, 측우기와 같은 과학 기구를 개발하도록 지원하였습니다. 또한, 음악과 예술을 장려하고, 법률과 제도를 정비하여 국가의 기틀을 다졌습니다. 세종대왕의 통치 아래 조선은 정치적 안정과 문화적 번영을 누릴 수 있었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질의 내용\n",
    "question = '세종대왕이 누구인지 설명해주세요'\n",
    "\n",
    "# 질의\n",
    "result = llm.invoke(question)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIgOfkp4LsGL"
   },
   "source": [
    "GPT‐4 에게 좀 더 복잡한 프롬프트를 전달하기 위해서 랭체인에서는 프롬프트 템플릿이라는 것을 사용합니다. 프롬프트 템플릿이란 말 그대로 GPT‐4 에게 입력을 전달하는 프롬프트의 템플릿을 만들어 두는 것을 의미합니다. 프롬프트 템플릿에서는 일종의 변수 (variables) 를 만들어두고, 정해진 템플릿 내에서 변수만 변경하여 GPT‐4 에게 입력을 전달하는 것이 가능합니다. 예를 들어, {who}라는 변수를\n",
    "두고, \"{who}가 누구인지 설명해주세요\"라는 템플릿을 만든다고 해봅시다. 이제 해당 템플릿에서 {who}라는 변수만 계속 변경하여 GPT‐4 에게 입력을 전달할 수 있습니다.\n",
    "다음은 프롬프트 템플릿을 만드는 과정입니다. 먼저 {} 로 감싼 변수를 두고, 템플릿을 만들어 template 이 라는 문자열에 저장한 뒤, PromptTemplate() 에 template 의 인자값으로 전달합니다. 그리고 사용할 변수명은 input_variables 의 값으로 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1753524262570,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "-9YbwBlILPeG",
    "outputId": "9f4234ca-3abc-4082-b0b0-096d8310961b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['who'] input_types={} partial_variables={} template='{who}가 누구인지 설명해주세요'\n"
     ]
    }
   ],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = \"{who}가 누구인지 설명해주세요\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(\n",
    "    template = template, input_variables = [\"who\"]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNfrBCjvMXxa"
   },
   "source": [
    "이렇게 만들어진 프롬프트 템플릿에 .format()을 명시적으로 추가하면 프롬프트 완성본을 미리 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1753524369002,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "xQaIerj7MKit",
    "outputId": "3be8c1da-addf-4fc4-b0f4-f74c5679a069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이순신가 누구인지 설명해주세요\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(who=\"이순신\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQH6bd-ZM1gu"
   },
   "source": [
    "이렇게 만들어진 프롬프트 템플릿은 ChatOpenAI()를 통해 생성한 llm 객체와 연결할 수 있습니다.\n",
    "직접 GPT‐4 를 호출하는 llm 객체와 프롬프트 템플릿을 연결하는 매개체를 랭체인에서는 개념적으로 체인 (Chain) 이라고 부릅니다. 체인을 생성하는 방법은 간단한데, 프롬프트 템플릿과 llm 객체 사이에 prompt | llm과 같이 |(파이프) 를 추가하는 것입니다. 이는 프롬프트를 모델에 전달한다는 의미를 담고 있습니다. 이렇게 생성된 llm_chain 객체는 앞서 llm 객체와 마찬가지로 invoke()를 통해 GPT‐4 에게 입력을 전달할 수 있습니다. 이번에는 프롬프트 템플릿을 사용하고 있으므로 프롬프트 템플릿의 변수 값도 전달해 줍니다. 여기서는 who의 값으로 \"이순신 장군\"을 전달했습니다. 프롬프트 템플릿이 \"{who}가 누구인지 설명해주세요\"라는 템플릿을 갖고 있으므로 결과적으로 GPT‐4 에는 \"이순신 장군가 누구인지 설명해주세요\"라는 입력이 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3723,
     "status": "ok",
     "timestamp": 1753524530982,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "DKB4VvSWMfbl",
    "outputId": "f66221fc-9c7d-42e0-eb9c-a17df0fd7be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이순신 장군은 조선 시대의 유명한 군인으로, 임진왜란 당시 조선 수군을 이끌어 일본군을 상대로 여러 차례 승리를 거둔 인물입니다. 그는 1545년에 태어나 1598년에 전사할 때까지 조선의 해군을 지휘하며 뛰어난 전략과 전술로 유명했습니다. 특히, 한산도 대첩, 명량 해전 등에서의 승리는 그의 지휘 능력을 잘 보여줍니다.\n",
      "\n",
      "이순신 장군은 거북선이라는 철갑선을 활용하여 일본군을 효과적으로 물리쳤으며, 그의 리더십과 용기는 오늘날까지도 많은 사람들에게 존경받고 있습니다. 그는 충무공이라는 시호를 받았으며, 한국 역사에서 가장 위대한 군사 지도자 중 한 명으로 평가받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 연결된 체인 생성\n",
    "llm_chain = prompt | llm\n",
    "result = llm_chain.invoke({\"who\": \"이순신 장군\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzXxxJ8dNVDv"
   },
   "source": [
    "llm_chain으로 invoke()를 실행할 때 실제 전달되는 프롬프트 또한 출력 결과로 확인하고 싶다면 invoke()를 호출할 때 config={'callbacks': [ConsoleCallbackHandler()]}를 사\n",
    "용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3616,
     "status": "ok",
     "timestamp": 1753524686136,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "LunQbUO3NN9B",
    "outputId": "61eb42be-63bd-4328-ed03-cf587422d465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"who\": \"이순신 장군\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"who\": \"이순신 장군\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 이순신 장군가 누구인지 설명해주세요\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [3.60s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"이순신 장군은 조선 시대의 유명한 군인으로, 임진왜란 당시 조선 수군을 이끌며 큰 공을 세운 인물입니다. 1545년에 태어나 1598년에 전사한 그는, 특히 한산도 대첩, 명량 해전, 노량 해전 등 여러 해전에서 혁혁한 전과를 올렸습니다. 이순신 장군은 그의 뛰어난 전략과 전술, 그리고 리더십으로 인해 조선의 해군력을 크게 강화하였고, 일본군의 침략을 효과적으로 막아냈습니다.\\n\\n그는 또한 거북선이라는 철갑선을 사용하여 해전에서 큰 이점을 얻었으며, 이는 세계 해전사에서도 주목받는 혁신적인 무기였습니다. 이순신 장군은 그의 충성과 용맹함으로 인해 한국 역사에서 가장 존경받는 인물 중 하나로 남아 있으며, 그의 삶과 업적은 오늘날까지도 많은 사람들에게 영감을 주고 있습니다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"이순신 장군은 조선 시대의 유명한 군인으로, 임진왜란 당시 조선 수군을 이끌며 큰 공을 세운 인물입니다. 1545년에 태어나 1598년에 전사한 그는, 특히 한산도 대첩, 명량 해전, 노량 해전 등 여러 해전에서 혁혁한 전과를 올렸습니다. 이순신 장군은 그의 뛰어난 전략과 전술, 그리고 리더십으로 인해 조선의 해군력을 크게 강화하였고, 일본군의 침략을 효과적으로 막아냈습니다.\\n\\n그는 또한 거북선이라는 철갑선을 사용하여 해전에서 큰 이점을 얻었으며, 이는 세계 해전사에서도 주목받는 혁신적인 무기였습니다. 이순신 장군은 그의 충성과 용맹함으로 인해 한국 역사에서 가장 존경받는 인물 중 하나로 남아 있으며, 그의 삶과 업적은 오늘날까지도 많은 사람들에게 영감을 주고 있습니다.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 220,\n",
      "                \"prompt_tokens\": 17,\n",
      "                \"total_tokens\": 237,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "              \"system_fingerprint\": \"fp_a288987b44\",\n",
      "              \"id\": \"chatcmpl-BxWA5gPJe8YaPO7geO0S8pSs3CUsu\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--d4ff69b9-9e3c-4324-a3cc-32f958318fec-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 17,\n",
      "              \"output_tokens\": 220,\n",
      "              \"total_tokens\": 237,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 220,\n",
      "      \"prompt_tokens\": 17,\n",
      "      \"total_tokens\": 237,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-2024-08-06\",\n",
      "    \"system_fingerprint\": \"fp_a288987b44\",\n",
      "    \"id\": \"chatcmpl-BxWA5gPJe8YaPO7geO0S8pSs3CUsu\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.60s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "result = llm_chain.invoke({\"who\": \"이순신 장군\"},\n",
    "                          config={\"callbacks\": [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k0xKzDLOC3U"
   },
   "source": [
    "답변을 얻기까지의 다양한 과정을 출력하는데 목적이 있는 코드이기 때문에 다양한 정보가 출력되는데,그중 “prompts” 에 해당하는 부분이 실제 GPT‐4 에 전달된 프롬프트이며, 여기서는 “Human: 이순신 장군가 누구인지 설명해주세요” 라는 프롬프트가 전달되었습니다.\n",
    "\n",
    "이번에는 과거 대화 내역을 반영하여 GPT‐4 와 대화할 수 있는 RunnableWithMessageHistory()\n",
    "에 대해 알아봅시다. 우선 history와 input이라는 두 개의 변수를 가지는 새로운 프롬프트 템플릿을\n",
    "선언합니다. 이때 history는 과거의 대화 내역을 지속적으로 누적할 변수입니다. input은 사용자\n",
    "의 최근 입력이 들어갈 변수입니다. 다시 말해 사용자가 GPT‐4 와 대화를 하면 할수록 사용자의 입력과 GPT‐4 의 답변을 포함한 모든 기록은 아래 템플릿에서 {history}에 누적되며, 현재의 입력하는 질문은 {input}에 들어가서 완성된 프롬프트가 GPT‐4 에게 전달됩니다. GPT‐4 는 이러한 프롬프트를 통해서 현재의 질문과 이전의 모든 대화 내역을 바탕으로 답변할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABGSWO04NqGT"
   },
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 생성\n",
    "template = \"\"\"아래는 사람과 AI의 친근한 대화입니다. AI의 이름은 위키독스봇 입니다.\n",
    "대화 문맥을 바탕으로 친절한 답변을 진행하세요.\n",
    "\n",
    "Current Conversation:\n",
    "{history}\n",
    "\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template, input_variables=['history', 'input']\n",
    ")\n",
    "\n",
    "# llm 객체를 새로 선언하고, 프롬프트 템플릿과 llm 객체를 연결합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksqcx51lPP_M"
   },
   "source": [
    "여기서 챗봇을 구현할 때 중요한 개념 중 하나인 ‘세션’ 에 대해서 설명해보겠습니다. 세션은 하나의 연속\n",
    "된 대화를 의미합니다. 예를 들어, 한 사용자가 챗봇과 대화를 시작해서 끝낼 때까지가 하나의 세션입니\n",
    "다. 세션을 사용하면 여러 사용자가 동시에 챗봇과 대화할 때 각 대화를 독립적으로 관리할 수 있습니다.\n",
    "세션은 온라인 채팅에서 각각의 독립적인 대화를 구분하는 개념입니다. 예를 들어봅시다.\n",
    "1. 사용자 A 가 챗봇과 대화를 시작합니다. 이것이 세션 1 입니다.\n",
    "2. 동시에 사용자 B 도 같은 챗봇과 대화를 시작합니다. 이는 세션 2 가 됩니다.\n",
    "3. 챗봇은 각 세션의 대화 내용을 따로 기억하고 관리합니다.이렇게 함으로써\n",
    "\n",
    "‐ 여러 사용자가 동시에 챗봇을 사용할 수 있습니다.\n",
    "\n",
    "‐ 챗봇은 각 사용자와의 대화 맥락을 헷갈리지 않고 유지할 수 있습니다.\n",
    "\n",
    "‐ 한 사용자의 대화가 다른 사용자의 대화에 영향을 주지 않습니다.\n",
    "\n",
    "코드에서 store 딕셔너리와 session_id가 이 기능을 구현하는 데 사용됩니다. store 딕셔너\n",
    "리는 여러 세션의 대화들을 관리합니다. 각 세션을 독립적으로 저장하기 위해서 딕셔너리의 키는 session_id이고, 딕셔너리의 값은 해당 세션의 대화 기록입니다. 이를 통해 여러 사용자와 동시에 독립적인 대화를 관리할 수 있습니다. 여기서는 \"test\"라는 session_id를 생성하여 해당 세션 내에서\n",
    "대화를 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJMmR4JBNvTj"
   },
   "outputs": [],
   "source": [
    "store = {}\n",
    "session_id = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qw95r7sQd8-"
   },
   "source": [
    "if session_id not in store: 조건문은 현재 session_id가 store 딕셔너리에 키로 존재\n",
    "하지 않는 경우를 확인합니다. 다시 말해 store 딕셔너리에 \"test\"라는 session_id가 아직 존재하\n",
    "지 않는 경우를 확인하며, 만약 아직 존재하지 않는다면 ChatMessageHistory()는 새로운 대화 기\n",
    "록 객체를 생성합니다. session_history = store[session_id]는 현재 세션의 대화 기록을\n",
    "session_history 변수에 할당합니다. 새 세션이었다면 방금 생성된 빈 ChatMessageHistory\n",
    "() 객체가 할당됩니다. 기존 세션이었다면 이전에 저장된 대화 기록 객체가 할당됩니다. 현재 코드가 실행되는 시점에서는 \"test\"라는 session_id는 신규 세션이므로 빈 ChatMessageHistory() 객체가 할당될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPYL9tllPVcn"
   },
   "outputs": [],
   "source": [
    "if session_id not in store:\n",
    "  store[session_id] = ChatMessageHistory()\n",
    "session_history = store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI_MaWaQQx63"
   },
   "source": [
    "실제호출할때는RunnableWithMessageHistory()를사용합니다. 입력으로앞서생성한chain\n",
    ", session_history, 그리고 프롬프트 템플릿에서 사용자의 입력에 사용할 변수인 \"input\"과 변수\n",
    "인 \"history\"를 지정하여 모두 연결해주는 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_dxkaCfPYZU"
   },
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNbASQTXTOOe"
   },
   "source": [
    "이렇게 생성된 RunnableWithMessageHistory() 객체는 호출 시의 앞서 실습한 체인과 마찬가지\n",
    "로 invoke()를 사용하여 호출합니다. 단, 해당 입력이 어떤 세션에서 사용되는지를 명시적으로 알려주\n",
    "기 위해서 config={\"configurable\": {\"session_id\": \"현재 질문이 어떤 세션에서 이\n",
    "루어지는지를 알려주는 세션 id\"}를 함께 전달해야 합니다. 챗봇에게 어디에서 만들어졌는지 질문\n",
    "을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1753526073209,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "6jWM9Td7RRJk",
    "outputId": "d952a598-1cf3-4921-b57e-6a21ea783445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 다양한 정보와 자료를 제공하기 위해 개발된 AI입니다. 저의 기반 기술은 여러 개발자들이 협력하여 만든 것으로, 특정한 장소에서 \"제작\"되었다기보다는 여러 곳에서 연구되고 발전되었습니다. 궁금한 점이 있으면 언제든지 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"input\": \"당신은 어디에서 만들었습니까?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATvj-jY-TTIG"
   },
   "source": [
    "이어서 푸른 바다를 주제로 시를 지어달라는 요청을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1753526229670,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "BLrL2vDPRpeP",
    "outputId": "da00a951-3ddb-40f4-ba03-a227070025ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "푸른 바다의 숨결 속에  \n",
      "잔잔한 파도는 속삭이고,  \n",
      "반짝이는 햇살은 웃음을 짓네.  \n",
      "수평선은 끝없는 꿈의 시작,  \n",
      "그곳에 마음을 띄워보아요.\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"input\" : \"푸른 바다를 주제로 감성적이고 짧은 시를 하나 지어주세요\"},\n",
    "    config = {\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M17FjdRdTxRL"
   },
   "source": [
    "이번에는 석양을 주제로도 해달라는 요청을 해봅시다. 이번 요청에서는 정확하게 무엇을 해달라고는 명\n",
    "시하지 않았습니다. 만약 이전 대화를 잘 기억하고 있다면 짧은 시를 지어달라는 요청임을 알고 석양을 주\n",
    "제로 짧은 시를 지어줄 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1753526284644,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "tMJH6KddTtN8",
    "outputId": "125cf1cb-9eb8-4f7e-f3bc-3518610dba65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "석양의 붉은 노을이 물든 하늘,  \n",
      "그 끝자락에 하루의 피로를 내려놓고,  \n",
      "서서히 가라앉는 태양의 온기 속에  \n",
      "마음은 고요히 하루를 닫는다.  \n",
      "삶은 또 다른 시작을 준비하네.\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"input\" : \"석양을 주제로 짧은 시를 하나 지어주세요\"},\n",
    "    config = {\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CrSxHcbT-0P"
   },
   "source": [
    "정상적으로 시를 작성합니다. 앞서 확인했던 프롬프트 템플릿에서 {history}의 위치. 즉, Current\n",
    "Conversation: 다음에 앞서 대화했던 내용이 누적되어 전달되었고, 과거 대화 내역을 바탕으로 석양\n",
    "을 주제로 삼행시를 지어 답변해주는 것을 확인할 수 있습니다. 이번에는 각 session_id별로 대화 기\n",
    "록을 저장하는 store를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1753526330505,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "6Tvijn0oT6ot",
    "outputId": "daa10775-c60b-406f-a560-39f2ff316d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': InMemoryChatMessageHistory(messages=[HumanMessage(content='당신은 어디에서 만들었습니까?', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요! 저는 다양한 정보와 자료를 제공하기 위해 개발된 AI입니다. 저의 기반 기술은 여러 개발자들이 협력하여 만든 것으로, 특정한 장소에서 \"제작\"되었다기보다는 여러 곳에서 연구되고 발전되었습니다. 궁금한 점이 있으면 언제든지 물어보세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 66, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BxWWUQUTDE1rsmkf53q4oPu4KdVZL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--43e10007-9ad1-4583-b5ad-3bdc8cdc0f19-0', usage_metadata={'input_tokens': 66, 'output_tokens': 68, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='푸른 바다를 주제로 감성적이고 짧은 시를 하나 지어주세요', additional_kwargs={}, response_metadata={}), AIMessage(content='푸른 바다의 숨결 속에  \\n잔잔한 파도는 속삭이고,  \\n반짝이는 햇살은 웃음을 짓네.  \\n수평선은 끝없는 꿈의 시작,  \\n그곳에 마음을 띄워보아요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 435, 'total_tokens': 492, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BxWZ1qf7ddFz55SHH6HXrJLli15Fh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--395311a2-efcd-411c-8ce4-4fdc4d6993dd-0', usage_metadata={'input_tokens': 435, 'output_tokens': 57, 'total_tokens': 492, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='석양을 주제로 짧은 시를 하나 지어주세요', additional_kwargs={}, response_metadata={}), AIMessage(content='석양의 붉은 노을이 물든 하늘,  \\n그 끝자락에 하루의 피로를 내려놓고,  \\n서서히 가라앉는 태양의 온기 속에  \\n마음은 고요히 하루를 닫는다.  \\n삶은 또 다른 시작을 준비하네.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 794, 'total_tokens': 864, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BxWZuLNP9ki7SrvpawyIe9Bt6REcr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bdea8881-dab3-462e-bef4-7bee40f46015-0', usage_metadata={'input_tokens': 794, 'output_tokens': 70, 'total_tokens': 864, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwSfjlMzUKp-"
   },
   "source": [
    "\"test\"라는 key값에 앞서 대화했던 모든 기록들이 저장 되어있습니다. 사용자의 입력은 HumanMessage(content='내용')에 저장되어 있고, 그에 대한 답변은 AIMessage(content='내용')에 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8j0dq-zTUBSe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAbbruOqyUpeaXwA7yDSVd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
