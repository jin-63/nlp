{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpPFyph-2aKP"
   },
   "source": [
    "## 크로스 인코더를 이용한 리랭킹\n",
    "### 크로스 인코더 기반의 리랭킹\n",
    "크로스 인코더 기반 리랭킹이라는 설명을 하기 위해서는 우선 이중 인코더 (bi‑encoder) 와 크로스 인코더 (cross‑encoder) 방식의 차이를 이해해야 합니다.\n",
    "\n",
    "검색 시스템의 기본이 되는 이중 인코더는 텍스트를 벡터로 변환하여 의미적 유사도를 계산하는 방식입\n",
    "니다. 우리가 지금까지 LangChain 의 Chroma와 OpenAIEmbeddings를 통해 사용하던 기본 검색 방\n",
    "식이 바로 이 이중 인코더입니다. 검색 과정에서 이중 인코더는 질문을 벡터로 변환하고, 데이터베이스의\n",
    "모든 문서들도 각각 벡터로 변환합니다. 예를 들어 “고양이의 수명” 이라는 질문은 하나의 벡터가 되고,\n",
    "데이터베이스의 각 문서 조각들도 각자의 벡터를 가지게 됩니다. 그런 다음 질문 벡터와 문서 벡터들 간\n",
    "의 코사인 유사도를 계산하여 가장 유사한 문서들을 찾아냅니다. 문서의 벡터를 미리 계산해두고 저장할\n",
    "수 있어 검색 속도가 매우 빠르다는 장점이 있지만, 질문과 문서를 독립적으로 처리하기 때문에 정확도 면\n",
    "에서는 한계가 있습니다.\n",
    "\n",
    "반대로 크로스 인코더는 질문과 문서를 따로 벡터화하지 않고 하나의 쌍으로 입력받아 직접적으로 관련성을 판단합니다. 이 방식은 두 텍스트의 관계를 동시에 고려하여 문맥을 더 깊이 이해하기 때문에 더 정\n",
    "확한 관련성 판단이 가능합니다. 하지만 치명적인 단점이 있습니다. 문서가 1000 개라면 검색어가 들어\n",
    "올 때마다 1000 번의 연산을 새로 해야 하므로, 실시간 검색 시스템의 첫 단계 검색기로는 사용할 수 없습\n",
    "니다.\n",
    "\n",
    "- 여기서 잠깐!! 두 방법 모두 일반적으로 BERT를 사용합니다. 이중 인코더는 BERT를 이용하여 각\n",
    "각 임베딩 한 후에 유사도를 계산하고, 크로스 인코더는 KorNLI 챕터에서 배웠던 방식처럼\n",
    "두 개의 텍스트 입력을 동시에 넣으면 스코어가 출력되는 방식입니다.\n",
    "\n",
    "이런 상황에서 리랭킹이라는 해결책이 등장합니다. 앞으로 우리 코드에서 사용할 BAAI/bgereranker-v2-m3는 크로스 인코더 모델로, 이를 2 단계 검색의 재정렬 단계에서 활용할 것입니다. 먼\n",
    "저 빠른 이중 인코더로 문서를 일부만 추려낸 다음, 이 적은 수의 문서에 대해서만 크로스 인코더를 적용하는 방식입니다.\n",
    "\n",
    "실제 예시를 들어보면, “고양이의 수명” 이라는 질문이 들어왔을 때 먼저 이중 인코더로 빠르게 4 개의 관\n",
    "련 문서를 찾습니다. 그런 다음 BAAI/bge-reranker가 이 4 개의 문서만을 질문과 쌍으로 만들어 더\n",
    "정교한 관련성을 계산합니다. 이때는 4 쌍만 평가하면 되므로 속도 문제가 없습니다. 이렇게 크로스 인코\n",
    "더의 정확도와 이중 인코더의 속도를 모두 활용할 수 있는 것이 바로 리랭킹의 핵심입니다. 이러한 이중\n",
    "필터링 과정을 통해 검색의 정확도를 크게 향상시킬 수 있으며, 이제 이 개념을 실제 코드로 구현해보도록\n",
    "하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AvS286P3EED"
   },
   "source": [
    "### 2. 패키지 설치 및 OpenAI키 값 설정\n",
    "랭체인 패키지와 벡터 데이터베이스를 위한 langchain_chroma, PDF를 앍기 위한 pypdf를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36542,
     "status": "ok",
     "timestamp": 1753955069362,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "m3wwcArU1nrg",
    "outputId": "ab4df3e2-1340-4417-c673-2d7fbb6fe8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_chroma\n",
      "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.72)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
      "Collecting chromadb>=1.0.9 (from langchain_chroma)\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.25.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (25.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.34.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=fdf89da53c133ff44737a018831931185104d3fa2e23a5857f3adc907e2ebf58\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pypdf, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, chromadb, langchain_community, langchain_chroma\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.5 langchain_community-0.3.27 langchain_openai-0.3.28 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypdf-5.9.0 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai langchain_community langchain_chroma pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1753955337953,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "E8JYvE8d3bM2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain.retrievers import ContextualCompressionRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpcBXolT4qlk"
   },
   "source": [
    "OpenAI의 키값을 셋팅 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753955397526,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "OCXFyF-O4Z8L"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'Openai_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuVUAC6G44xQ"
   },
   "source": [
    "### 3. 데이터 다운로드\n",
    "데이터는 2023_ 북한인권보고서.pdf 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1753955545579,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "XGWEM3kp425F",
    "outputId": "b5606011-d8e6-415b-869d-15937e8f6809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_북한인권보고서.pdf 다운 완료!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/llama-index-tutorial/llama-index-tutorial/raw/main/ch07/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\"\n",
    "filename = \"2023_북한인권보고서.pdf\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(filename, \"wb\") as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "print(f\"{filename} 다운 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDa94Pou5chH"
   },
   "source": [
    "###3. 거대 언어 모델과 임베딩 설정\n",
    "랭체인을 사용하여 사용할 각종 설정들의 값을 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 33603,
     "status": "ok",
     "timestamp": 1753955952501,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "K9x-qf2l5XKv"
   },
   "outputs": [],
   "source": [
    "# LangChain의 LLM과 임베딩 모델 설정\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0.2)\n",
    "embed_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# 문서 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 100)\n",
    "\n",
    "# PDF 문서를 읽고 벡터 인덱스 생성\n",
    "loader = PyPDFLoader(\"2023_북한인권보고서.pdf\")\n",
    "documents = loader.load()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "vector_store = Chroma.from_documents(chunks, embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz0e7SeAI4CU"
   },
   "source": [
    "문서처리를위한chunk_size=300과chunk_overlap=100설정은RecursiveCharacterTextSplitter\n",
    "에서 적용됩니다. 길이 300 기준으로 문서를 나누고 길이 100 자의 문자열을 중복되게 하여, 나중에 문서를 검색할 때 문맥이 끊기지 않도록 합니다\n",
    "\n",
    "이렇게설정한후, PyPDFLoader로PDF파일을읽어들이고load()로텍스트를추출합니다. 추출된텍스트는 text_splitter.split_documents()를 통해 분할되고, Chroma.from_documents\n",
    "()를 통해 벡터 인덱스로 변환되는데, 이 과정에서 위에서 설정한 임베딩 모델과 청크 설정이 모두 적용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVq68RKGI3rB"
   },
   "source": [
    "###4. 리랭킹 구현하기\n",
    "리랭킹을 사용하지 않는 기본 검색 엔진과 리랭킹을 사용하는 검색 엔진을 둘 다 별도로\n",
    "구현하여 검색 결과의 차이를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1753961111899,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "oMIdG3mP6yvo"
   },
   "outputs": [],
   "source": [
    "# 기본 검색 엔진 (리랭킹 없음)\n",
    "basic_retriever = vector_store.as_retriever(search_kwargs = {\"k\":4})\n",
    "\n",
    "# Reranker 설정\n",
    "cross_encoder = HuggingFaceCrossEncoder(model_name = \"BAAI/bge-reranker-v2-m3\")\n",
    "reranker = CrossEncoderReranker(model=cross_encoder, top_n=2)\n",
    "\n",
    "# 리랭킹이 포함된 검색 엔진\n",
    "rerank_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor = reranker,\n",
    "    base_retriever = basic_retriever\n",
    ")\n",
    "\n",
    "# 최종 답변 생성 함수\n",
    "def generate_answer(query:str, documents:List[Document]) ->str:\n",
    "  context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "  prompt = f\"\"\"다음 검색 결과를 바탕으로 질문에 답변해주세요.\n",
    "  검색 결과의 정보를 최대한 사용하고, 없는 정보는 답변하지 마세요.\n",
    "\n",
    "  검색결과:\n",
    "  {context}\n",
    "\n",
    "  질문: {query}\n",
    "\n",
    "  답변:\"\"\"\n",
    "\n",
    "  response = llm.invoke(prompt)\n",
    "  return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OloGY81FKsWS"
   },
   "source": [
    "basic_retriever는 리랭킹을 사용하지 않는 기본적인 벡터 검색만 수행하는 리트리버로,\n",
    "search_kwargs={\"k\": 4}는 임베딩 유사도를 기준으로 상위 4 개의 가장 관련성 높은 문서 조\n",
    "각을 찾아내도록 설정합니다. 이 과정에서는 텍스트를 벡터로 변환하고 코사인 유사도를 계산하여 가장 가까운 문서들을 찾아냅니다. 이 리트리버는 단순하지만 빠른 검색이 가능합니다.\n",
    "\n",
    "cross_encoder와 reranker 객체는 아래에서 구현할 리랭킹을 사용하는 검색엔진rerank_retriever에 서 리 랭 킹 을 위 해 서 사 용 될 크 로 스 인 코 더 모 델 입 니 다. BAAI/bgereranker-v2-m3 모델을 사용하여 문장 간의 의미적 관계를 더 깊이 이해하고 정확한 순위를 매깁니다. 크로스 인코더 방식이기 때문에 질문과 문서를 함께 분석하여, 단순한 벡터 유사도보다 더 정확한 관련성 판단이 가능하며, top_n=2 설정으로 가장 관련성 높은 2 개만 선택하도록 준비합니다.\n",
    "\n",
    "rerank_retriever는 리랭킹을 사용하는 검색 엔진으로, basic_retriever와 동일한 벡터 검색\n",
    "방식에위에서준비한reranker객체(즉,크로스인코더모델)를ContextualCompressionRetriever\n",
    "를 통해 추가하여 더 정교한 검색을 구현합니다. 기본 리트리버가 4 개의 문서를 찾은 후 reranker 로 결과를 정제하여 더 정확한 검색 결과를 제공합니다. 이러한 이중 필터링이라는 리랭킹 과정을 통해 리랭킹을 사용하지 않는 basic_retriever 검색 대비 검색의 정확도를 향상시킬 수 있습니다. 하지만 리랭킹\n",
    "과정 때문에 basic_retriever보다 더 많은 처리 시간을 필요로 합니다. 이는 기본 검색만 수행하는\n",
    "basic_retriever와는 달리 기본 검색 이후 크로스 인코더 모델에 해당하는 reranker 객체를 한\n",
    "번 더 사용하기 때문입니다.\n",
    "\n",
    "우선 리랭킹을 사용하지 않는 검색 엔진 basic_retriever를 사용하였을 때의 답변과 답변에 참고한 검색 결과를 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2422,
     "status": "ok",
     "timestamp": 1753961115649,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "rNpmyJHGKkCD",
    "outputId": "acf38ce9-958c-4a54-fa4c-2e4f66a00e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 기본 검색 엔진 검색 결과\n",
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "\n",
      "답변: 2019년 말 평양시 소재 기업소에서 일하던 노동자는 매월 쌀 6㎏, 기름 5ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리를 배급받았다는 증언이 있습니다.\n",
      "\n",
      "검색된 문서:\n",
      "\n",
      "검색 문서 1:\n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      "----\n",
      "\n",
      "검색 문서 2:\n",
      "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
      "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "----\n",
      "\n",
      "검색 문서 3:\n",
      "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
      "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
      "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
      "----\n",
      "\n",
      "검색 문서 4:\n",
      "한 달을 생활하기에 부족한 금액이었다고 하였다. 2018년 양강도의 \n",
      "무역사업소에서는 1년치 노동 보수와 배급을 한 번에 지급하였다고 \n",
      "하는데, 지급된 금액은 노동자 1명에게 1,800위안으로 약 300만원 \n",
      "정도였다고 하였다. 2019년 양강도의 합영회사는 노동자에게 매달 \n",
      "9~12만원의 보수를 지급하고, 1년에 한번 쌀 25kg을 지급하였다는 \n",
      "진술이 있었다. 또한 2020년 합영회사에서는 보수를 성과만큼 받았\n",
      "다고 하는데, 숙련공은 350위안, 쌀 100kg을 살 수 있을 정도의 돈\n",
      "을 받는 경우도 있었다고 하였다.\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 실행\n",
    "query = \"19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\"\n",
    "\n",
    "print(\"=== 기본 검색 엔진 검색 결과\")\n",
    "basic_documents = basic_retriever.invoke(query)\n",
    "basic_response = generate_answer(query, basic_documents)\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"\\n답변: {basic_response}\")\n",
    "print(f\"\\n검색된 문서:\")\n",
    "for i, doc in enumerate(basic_documents):\n",
    "  print(f\"\\n검색 문서 {1+i}:\")\n",
    "  print(doc.page_content)\n",
    "  print((\"----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8636GdZNSqk"
   },
   "source": [
    "query 변수에 “19 년 말 평양시 소재 기업소에서 달마다 배급받은 음식” 이라는 구체적인 질문을 저장합\n",
    "니다. 이 질문은 시기 (19 년 말), 장소 (평양시), 대상 (기업소), 내용 (배급받은 음식) 이 모두 명시된 구체적인 검색 요청입니다. 이어서 basic_retriever.invoke(query)를 통해 기본 벡터 검색을 수행합니다. 이때 내부적으로는 입력된 질문을 OpenAI 의 임베딩 모델로 벡터화하고, Chroma 벡터 데이터베이스에서 코사인 유사도를 계산한 후, 유사도가 높은 상위 4 개 문서를 추출하여 basic_documents 변수에 저장합니다. 이 과정은 앞서 설정한 search_kwargs={\"k\": 4} 파라미터에 의해 제어됩니다.\n",
    "\n",
    "검색이 완료되면 generate_answer(query, basic_documents)를 호출하여 검색된 문서들\n",
    "을 바탕으로 최종 답변을 생성합니다. 이 함수 내부에서는 4 개의 검색된 문서 내용을 하나의 컨텍스트로 결합하고, “검색 결과를 바탕으로 답변하라” 는 지시사항과 함께 프롬프트를 구성한 후, GPT‑4o 모델에 전송하여 자연어 답변을 생성하고 basic_response 변수에 저장합니다.\n",
    "\n",
    "마지막으로 입력된 질문, LLM 이 생성한 최종 답변, 검색에 사용된 4 개 문서의 내용을 출력합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFBKj-VvNi9u"
   },
   "source": [
    "기본 검색에서는 4 개의 문서가 모두 반환되었는데, 벡터 유사도 순위를 살펴보면 다음과 같습니다:\n",
    "- 검색 문서 1: 2019 년 평양의 외화벌이 사업소 보수 관련 내용으로 “음식 배급” 과는 직접적인 관련이 없\n",
    "습니다.\n",
    "- 검색 문서 2: 2019 년 평양시 기업소의 구체적인 배급량이 명시된 가장 중요한 문서입니다. 질문에 부합\n",
    "하는 내용입니다.\n",
    "- 검색 문서 3: 평양시의 일반적인 배급 시스템에 대한 설명으로, 맥락은 관련있지만 구체적인 배급량 정\n",
    "보는 없습니다.\n",
    "- 검색 문서 4: 양강도 합영회사 관련 내용으로 지역과 기관 유형이 모두 다릅니다.\n",
    "\n",
    "기본 벡터 검색에서는 가장 중요한 검색 문서 2 가 2 순위에 배치되었고, 상대적으로 관련성이\n",
    "낮은 문서 1 이 1 순위에 올라온 것을 볼 수 있습니다. 이번에는 리랭킹을 사용하는 검색 엔진인\n",
    "rerank_retriever를 사용하였을 때의 답변과 답변을 위해 참고한 검색 결과를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10076,
     "status": "ok",
     "timestamp": 1753961127387,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "eH7jwDrgM2dP",
    "outputId": "feab93b6-c3da-4518-abd7-982063aacd48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== 리랭킹 후 검색결과 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "답변: 2019년 말 평양시 소재 기업소에서 일하던 노동자는 매월 쌀 6㎏, 기름 5ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 등을 배급받았습니다.\n",
      "\n",
      "검색된 문서:\n",
      "\n",
      "검색 문서 1\n",
      "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
      "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "------\n",
      "\n",
      "검색 문서 2\n",
      "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
      "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
      "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n==== 리랭킹 후 검색결과 ====\")\n",
    "rerank_documents = rerank_retriever.invoke(query)\n",
    "rerank_response = generate_answer(query, rerank_documents)\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {rerank_response}\")\n",
    "print(\"\\n검색된 문서:\")\n",
    "for i, doc in enumerate(rerank_documents):\n",
    "  print((f\"\\n검색 문서 {i+1}\"))\n",
    "  print(doc.page_content)\n",
    "  print(\"------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip6Jx438O5qs"
   },
   "source": [
    "크로스 인코더 리랭킹 후에는 문서 수가 4 개에서 2 개로 줄어들면서 리랭킹을 사용하지 않는 기본 검색에\n",
    "서 2 순위였던 가장 중요한 문서 (구체적 배급량 정보) 가 1 순위로 올라왔습니다. 그 외에 문서 수가 4 개\n",
    "에서 2 개로 줄어드는 과정에서 외화벌이 사업소 현금 지급 관련 문서 (기본 검색 문서 1) 와 양강도 합영\n",
    "회사 관련 문서 (기본 검색 문서 4) 가 제거되었습니다. 결론적으로 리랭킹 후에는 실제 답변에 사용되는\n",
    "핵심 문서 (기존 검색 엔진에서의 검색 문서 2 번) 가 최고 순위인 검색 문서 1 번으로 올라온 것을 확인할\n",
    "수 있습니다.\n",
    "이처럼 리랭킹은 기존의 검색 엔진에서 실제 질문과 연관된 문서들을 필터링 할 수 있는 더 강력한 모델을\n",
    "두번째 검색 모델로 두어서 검색 성능을 높이므로서 답변에서의 오류를 줄일 수 있는 방법입니다. 이어서\n",
    "검색 성능을 높일 수 있는 또 다른 방법인 하이드 (HyDE) 에 대해서 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isHWWGWwOZhn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWAiG6uAQPRvRziIIeaYaY",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
