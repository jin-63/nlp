{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzRJMwwBg7tQ"
   },
   "source": [
    "## RAG 성능 올리는 기술(LLM 기반의 리랭킹)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kX-PN5BBhGIO"
   },
   "source": [
    "###1. LLM기반의 리랭킹\n",
    "LLM 기반 리랭킹은 대규모 언어 모델 (LLM) 을 사용해 초기 검색 결과를 다시 평가하고, 사용자의 질문과\n",
    "가장 관련이 높은 순서로 결과를 정렬하는 방법입니다. 초기 검색에서는 임베딩 모델 (주로 BERT 류의 문\n",
    "서 임베딩 모델) 을 이용한 유사도 계산이 사용되지만 LLM 과 비교하면 상대적으로 정확도가 떨어집니다.\n",
    "따라서 LLM 기반 리랭킹은 임베딩 모델의 초기 검색 결과를 보완하기 위해 사용합니다. 이 과정은 다음과\n",
    "같이 진행됩니다\n",
    "\n",
    "- 초기 검색 결과 준비: 임베딩 기반의 검색 시스템에서 반환된 상위 몇 개의 결과 (예: Top‑4, Top‑6 등) 를 입력으로 사용합니다.\n",
    "\n",
    "- LLM 을 통한 검색 결과 순위 조정: LLM 은 초기 검색 결과를 전체적으로 검토합니다. 예를 들어, 사용자\n",
    "가 “초보자를 위한 요리법” 을 검색했을 때, 임베딩 모델을 통한 검색 결과로 “고급 프랑스 요리 과정” 과\n",
    "“간단한 샌드위치 만들기” 가 반환되었다면, 초기 임베딩 모델을 통한 검색에서는 “고급 프랑스 요리 과\n",
    "정” 이 더 높은 순위를 받았을 수 있습니다. “요리 과정” 과 “요리법” 이 비슷한 의미를 가지고 있기 때문입니다. 하지만 LLM 은 사용자의 질문과 내용을 의미적으로 비교한 후, “간단한 샌드위치 만들기” 가 “초보자” 라는 점을 감안하면, 더 적합하다고 판단하고 더 높은 점수를 줄 수 있습니다.\n",
    "\n",
    "-  점수 기반 재정렬: LLM 이 새로 계산한 점수를 기준으로 기존의 임베딩 모델을 통한 검색 결과를 다시 정렬합니다. 예를 들어, LLM 이 관련성 점수를 1~10 으로 매겼다면, 점수가 높은 순서대로 검색 결과를 배열\n",
    "합니다. 이때 점수가 낮은 결과는 최종 목록에서 제외될 수도 있습니다. 실습을 통해 자세히 알아보겠습\n",
    "니다.\n",
    "\n",
    "각 문서마다 이러한 점수 계산이 필요하다 보니, LLM 호출 횟수가 증가하게 될 수 있음을 유의해야 합니\n",
    "다. 이를 구체적으로 살펴보기 위해 임베딩 검색으로 상위 4 개의 문서를 가져온 후 RAG 를 수행하는 과정\n",
    "을 비교해보겠습니다\n",
    "\n",
    "‑ 벡터 검색으로 문서 4 개를 찾아옵니다\n",
    "\n",
    "‑ LLM 호출 1 회: 검색된 4 개 문서 전체를 바탕으로 답변을 생성합니다\n",
    "\n",
    "‑ 총 LLM 호출: 1 회\n",
    "\n",
    "‑ 벡터 검색으로 문서 4 개를 찾아옵니다\n",
    "\n",
    "‑ LLM 호출 4 회: 각 문서와 질문의 관련성을 1‑10 점 사이로 평가합니다\n",
    "\n",
    "‑ LLM 호출 1 회: 관련성 점수가 높은 상위 2개 문서만으로 답변을 생성합니다\n",
    "\n",
    "‑ 총 LLM 호출: 5 회\n",
    "\n",
    "LLM 기반 리랭킹은 정확도는 높아지지만 각 문서의 관련성 평가와 최종 답변 생성까지 총 5 번의 LLM 호\n",
    "출이 필요해 비용과 시간이 증가하게 됩니다. 이제 본격적으로 실습을 진행해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx8T_KwxnmV1"
   },
   "source": [
    "###2. 패키지 설치 및 OpenAI키 값 설정\n",
    "랭체인 패키지와 벡터 데이터베이스를 위한 langchain_chroma, PDF 를 읽기 위한 pypdf 를\n",
    "설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47518,
     "status": "ok",
     "timestamp": 1753867112200,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "Ny8R_OW6g6yL",
    "outputId": "e6fe4ea5-17a1-4b87-deb4-6392e2abc72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_chroma\n",
      "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.72)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.97.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
      "Collecting chromadb>=1.0.9 (from langchain_chroma)\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.74.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (3.11.1)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.25.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (25.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.34.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=0e35f76ac69042235e60d78995f78c66bc5c80466c234db0147de9220dab0f56\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pypdf, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, langchain_openai, chromadb, langchain_community, langchain_chroma\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.5 langchain_community-0.3.27 langchain_openai-0.3.28 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypdf-5.9.0 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai langchain_community langchain_chroma pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xx5KBgGn5Tb"
   },
   "source": [
    "실습을 위해 필요한 패키지들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YGXOJVwn3PT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o7icQm6o8cd"
   },
   "source": [
    "OpenAI의 Key값을 셋팅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZtMNBLPon64"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'Openai_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmSa_OHipJy4"
   },
   "source": [
    "###2. 데이터 다운로드\n",
    "사용할 데이터는 2023_북한인권보고서.pdf입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1753867550434,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "29TgfLTgpIgB",
    "outputId": "f292a528-5218-475f-b5a5-dbc34aa4f877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023_북한인권보고서 다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 분석할 PDF 파일을 웹에서 다운로드.\n",
    "url = \"https://github.com/llama-index-tutorial/llama-index-tutorial/raw/main/ch07/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\"\n",
    "filename = \"2023_북한인권보고서\"\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(filename, \"wb\") as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "print(f\"{filename} 다운로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TDbPa-fpx7T"
   },
   "source": [
    "###3. 거대언어모델과 임베딩 설정\n",
    "랭체인을 사용하여 사용할 각종 설정들의 값을 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9_O70IVpvrn"
   },
   "outputs": [],
   "source": [
    "# LangChain의 LLM과 임베딩 모델 설정\n",
    "llm = ChatOpenAI(model = 'gpt-4o', temperature=0.2) # gpt-4o를 언어 모델로 사용\n",
    "embed_model = OpenAIEmbeddings(model = 'text-embedding-3-large') # 임베딩 모델 사용\n",
    "\n",
    "# 문서 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300, # 문서를 300자 단위로 분할\n",
    "    chunk_overlap = 100, # 문맥 유지를 위해서 청크간 100자 중복\n",
    ")\n",
    "\n",
    "#PDF 문서를 읽고 벡터 인덱스 생성\n",
    "loader = PyPDFLoader(\"2023_북한인권보고서\") # PDF 문서 로더\n",
    "documents = loader.load() # 문서에서 텍스트 추출\n",
    "chunks = text_splitter.split_documents(documents) # 문서 분할\n",
    "vector_store = Chroma.from_documents(chunks, embed_model) # - 각 문서 청크를 embed_model로 벡터화 - 벡터와 원본 문서를 Chroma에 저장\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffca6m8mrpB_"
   },
   "source": [
    "랭체인을 통해 각 구성 요소를 개별적으로 설정합니다. ChatOpenAI를 통해 이번에 사용할 LLM을 OpenAI의 GPT-4o로 설정하고, OpenAIEmbeddings를 통해 앞으로 사용할 임베딩 모델을 OpenAI의 text-embedding-3-large로 설정하였습니다.\n",
    "\n",
    "문서처리를위한chunk_size=300과chunk_overlap=100설정은RecursiveCharacterTextSplitter에서 적용됩니다. 길이 300 기준으로 문서를 나누고 길이 100 자의 문자열을 중복되게 하여, 나중에 문서를 검색할 때 문맥이 끊기지 않도록 합니다\n",
    "\n",
    "이렇게 설정한 후,PyPDFLoader로PDF파일을읽어들이고load()로 텍스트를 추출합니다. 추출된 텍스트는 text_splitter.split_documents()를 통해 분할되고, Chroma.from_documents()를 통해 벡터 인덱스로 변환되는데, 이 과정에서 위에서 설정한 임베딩 모델과 청크 설정이 모두 적용됩니다. 이렇게 생성된 인덱스는 이후 SemanticRanker 클래스에서 벡터 유사도 검색의 기반이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2D7-vm7seLk"
   },
   "source": [
    "###4. 리랭킹 구현하기\n",
    "이제 리랭킹을 위한 모듈 두 가지를 구현합니다. 먼저 구현할 DocumentScorer는 문서 검색 결과를 LLM 으로 재평가하는 리랭킹을 수행하는 모듈입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieNfefASrTvY"
   },
   "outputs": [],
   "source": [
    "class DocumentScorer:\n",
    "  # LLM을 사용해 문서의 관련성을 정밀하게 평가하고 점수를 매기는 클래스\n",
    "\n",
    "  def __init__(self, llm):\n",
    "    self.llm = llm\n",
    "\n",
    "  def evaluate_document(self, query: str, content: str) -> float:\n",
    "    # LLM을 사용해 문서와 쿼리 간의 의미적 관련성을 1-10점으로 평가\n",
    "    prompt = f\"\"\"\n",
    "    아래 주어진 질문과 문서의 관련성을 평가해 주세요.\n",
    "\n",
    "    [평가 기준]\n",
    "    - 문서가 질문에서 요구하는 정보를 직접적으로 포함하면 8-10점\n",
    "    - 문서가 질문과 관련된 맥락을 포함하지만 직접적인 답이 아니면 4-7점\n",
    "    - 문서가 질문과 거의 관련이 없으면 1-3점\n",
    "\n",
    "    [주의 사항]\n",
    "    - 단순히 비슷한 단어가 등장하는 것은 높은 점수의 근거가 될 수 없습니다.\n",
    "    - 질문의 의도와 문맥을 정확히 파악하여 평가해주세요\n",
    "    - 시간, 장소, 수치 등 구체적인 정보의 일치 여부를 중요하게 고려해 주세요\n",
    "\n",
    "    질문: {query}\n",
    "    문서: {content}\n",
    "\n",
    "    응답은 반드시 다음 JSON 형식이어야 합니다. 백틱은 쓰지 마십시오.:\n",
    "    {{\"relevance_score\": float}}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "      # LLM에 프롬프트를 전송하고 JSON 형식의 응답을 받음\n",
    "      response = self.llm.invoke(prompt)\n",
    "      # 응답에서 relevance_score 값을 추출\n",
    "      score = json.loads(response.content)[\"relevance_score\"]\n",
    "      # 점수를 float로 변환하여 반환\n",
    "      return float(score)\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error occurred: {str(e)}\")\n",
    "      return 5.0 # 에러 발생시 중간 점수로 처리하여 시스템 안정성 유지\n",
    "\n",
    "  def postprocess_documents(self, documents: List[Document], query:str) ->List[Document]:\n",
    "    # 벡터 검색으로 찾은 4개 문서를 LLM으로 재평가 하여 최적의 2개를 선택\n",
    "    print('\\n====LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다.====')\n",
    "    scored_docs = []\n",
    "    for doc in documents:\n",
    "      # 현재 처리 중인 문서에서 순수 텍스트 컨텐츠만 추출\n",
    "      content = doc.page_content\n",
    "      # LLM으로 문서 관련성 점수 계산 (1-10 사이 점수)\n",
    "      score = self.evaluate_document(query, content)\n",
    "      # 디버깅/ 모니터링을 위해 각 문서의 내용과 점수를 출력\n",
    "      print(f\"\\nLLM 기반의 평가: \\n{content}\\n =>점수: {score}\\n\")\n",
    "      # 현재 문서와 계산된 점수를 튜플로 저장\n",
    "      scored_docs.append((doc, score))\n",
    "\n",
    "    # 모든 문서를 점수 기준 내림차순으로 정렬하고 상위 2개만 선택하여 반환\n",
    "    ranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse = True)\n",
    "    return [doc for doc, _ in ranked_docs[:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhOp6oG33tRw"
   },
   "source": [
    "먼저 DocumentScorer 내부의 evaluate_document를 주목해봅시다. 내부에 LLM 이 검색 결과에\n",
    "대해서 점수를 측정하는 프롬프트가 작성되어져 있습니다. prompt라는 변수에 작성된 이 프롬프트에\n",
    "는 입력받은 질문과 검색된 문서의 관련성을 1 점부터 10 점까지의 점수로 평가합니다. 프롬프트에서는\n",
    "LLM 에게 문서가 질문이 원하는 정보를 직접 포함하면 8‑10 점, 관련 맥락만 있으면 4‑7 점, 거의 관련 없\n",
    "으면 1‑3 점을 주도록 지시하고 있습니다.\n",
    "실제로 DocumentScorer의 실행 순서는 내부의 postprocess_documents가 먼저 실행되고,\n",
    "postprocess_documents 내부에서 또 다른 메소드인 evaluate_document를 호출하는 구조입\n",
    "니다. postprocess_documents에서는 사용자의 질문과 해당 질문으로부터 임베딩 모델이 찾은 초\n",
    "기 검색 결과로 4 개의 문서가 전달됩니다. 이 4 개의 검색 결과가 위에서 설명한 evaluate_document\n",
    "로 전달하고, evaluate_document가 사용자 질문과 각각의 문서에 대해서의 연관성에 대한 평가를\n",
    "마치면, LLM 으로부터 받은 점수와 평가 과정을 출력합니다. 그 후 높은 점수 기준으로 정렬하여 가장 높은 점수를 받은 2 개의 문서만 반환합니다. 이렇게 초기 검색 결과 4 개는 LLM 으로 다시 관련성 점수가 측\n",
    "정되어 관련성 점수가 높은 2 개의 문서만 반환되는 리랭킹 과정을 거칩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-en0qkoG3xLj"
   },
   "source": [
    "지금까지 검색 결과 4 개에 대해서 리랭킹 과정을 수행하는 리랭킹 모듈 DocumentScorer에 대해서\n",
    "설명했습니다. 이번에는 검색 결과 4 개를 입력으로 위의 리랭킹 모듈을 실제로 호출하는 역할을 하는\n",
    "SemanticRanker에 대해서 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEBzgpCExWxR"
   },
   "outputs": [],
   "source": [
    "class SemanticRanker:\n",
    "  # 벡터 검색 결과에 LLM기반 의미적 평가를 적용하여 최적의 문서를 선별하는 시스템\n",
    "  def __init__(self, vector_store, scorer):\n",
    "    # 생성자에서 벡터 검색용 저장소와 LLM 기반 문서 평가가 인스턴스를 받아 저장\n",
    "    self.vector_store = vector_store # 벡터 검색용 저장소\n",
    "    self.scorer = scorer\n",
    "\n",
    "  def retrieve(self, query: str) -> List[Document]:\n",
    "    # 벡터 검색으로 유사도 기반 후보 문서 4개를 추출하고 LLM으로 재평가\n",
    "    vector_results = self.vector_store.similarity_search(query, k=4)\n",
    "\n",
    "    # 초기 벡터 검색 결과를 디버깅/ 분석용으로 출력\n",
    "    print(\"\\n==== 실제 검색 결과 (Top4) ====\")\n",
    "    for i, doc in enumerate(vector_results, 1):\n",
    "      print(f\"\\n검색 문서 {i}:\")\n",
    "      print(doc.page_content)\n",
    "\n",
    "    # LLM으로 문서들을 재평가하고 재정렬하여 최적의 2개 선택\n",
    "    reranked_results = self.scorer.postprocess_documents(vector_results, query)\n",
    "\n",
    "    # 최종 선별되 문서를 디버깅 /분석용으로 출력\n",
    "    print(\"\\n==== LLM의 리랭킹 결과(Top2) ====\")\n",
    "    for i, doc in enumerate(reranked_results, 1):\n",
    "      print(f\"\\n검색 문서 {i}:\")\n",
    "      print(doc.page_content)\n",
    "\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj0zjRix5rx1"
   },
   "source": [
    "실제실행순서는SemanticRanker의retrieve에서DocumentScorer의postprocess_documents\n",
    "를 호출하는 순서입니다. SemanticRanker는 벡터 검색 후에 LLM 기반 평가를 실행하는 모듈입니다.\n",
    "실제 검색이 어떻게 수행되는지 설명해봅시다.\n",
    "\n",
    "SemanticRanker가 실 행 되 면 retrieve 메 소 드 가 호 출 되 며 내 부 에 서 vector_store.\n",
    "similarity_search를 통해 먼저 벡터 기반 검색을 수행하여 상위 4 개의 문서를 가져옵니다. 이때\n",
    "k=4 파라미터로 상위 4 개만 추출하도록 지정했습니다. 추출된 4 개의 문서는 디버깅을 위해 “실제 검색\n",
    "결과 (Top 4)” 라는 제목으로 출력됩니다.\n",
    "\n",
    "그 다음, 앞서 설명한 DocumentScorer의 postprocess_documents를 호출하여 이 4 개의 문서\n",
    "를 LLM 으로 재평가합니다. 재평가가 완료되어 상위 2 개의 문서가 선택되면 “LLM 의 리랭킹 결과 (Top\n",
    "2)” 라는 제목으로 최종 선택된 문서들을 출력하고 이를 반환합니다.\n",
    "\n",
    "이런 방식으로 SemanticRanker는 벡터 검색으로 1 차 필터링을 하고, LLM 으로 2 차 정밀 평가를 수\n",
    "행하여 사용자 질문에 가장 적합한 문서를 찾아내는 2 단계 검색을 구현하고 있습니다.\n",
    "\n",
    "이제 위에서 설명한 두 개의 리랭킹 모듈 DocumentScorer와 SemanticRanker를 실제 객체로 선\n",
    "언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwFWYFPB5m13"
   },
   "outputs": [],
   "source": [
    "# 문서 평가 및 검색 시스템 선언 (초기화)\n",
    "scorer = DocumentScorer(llm) # LLM기반 문서 평가기 생성\n",
    "ranker = SemanticRanker(vector_store, scorer) # 벡터 검색어와 LLM평가를 결합한 시스템 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0IR2FRZ6LeP"
   },
   "source": [
    "모듈 선언 단계에서는 두 단계의 객체 생성이 일어납니다. DocumentScorer 객체를 scorer라\n",
    "는 이름으로 생성하고, 이 scorer를 실제로 실행할 SemanticRanker에 전달하여 벡터 검색과 리\n",
    "랭킹을 결합된 시스템 객체 ranker를 생성합니다. 리랭킹 모듈들을 실제로 실행해보겠습니다.\n",
    "generate_final_answer 함수를 정의하여 선택된 문서들로 최종 답변을 생성하는 기능을 구현합\n",
    "니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6887,
     "status": "ok",
     "timestamp": 1753872591986,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "fAXcUQpS6Go0",
    "outputId": "1da54a25-112d-49ba-c09e-e44cb178e224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\n",
      "\n",
      "==== 실제 검색 결과 (Top4) ====\n",
      "\n",
      "검색 문서 1:\n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      "\n",
      "검색 문서 2:\n",
      "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
      "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "\n",
      "검색 문서 3:\n",
      "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
      "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
      "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
      "\n",
      "검색 문서 4:\n",
      "한 달을 생활하기에 부족한 금액이었다고 하였다. 2018년 양강도의 \n",
      "무역사업소에서는 1년치 노동 보수와 배급을 한 번에 지급하였다고 \n",
      "하는데, 지급된 금액은 노동자 1명에게 1,800위안으로 약 300만원 \n",
      "정도였다고 하였다. 2019년 양강도의 합영회사는 노동자에게 매달 \n",
      "9~12만원의 보수를 지급하고, 1년에 한번 쌀 25kg을 지급하였다는 \n",
      "진술이 있었다. 또한 2020년 합영회사에서는 보수를 성과만큼 받았\n",
      "다고 하는데, 숙련공은 350위안, 쌀 100kg을 살 수 있을 정도의 돈\n",
      "을 받는 경우도 있었다고 하였다.\n",
      "\n",
      "====LLM이 4개의 검색 결과에 대해서 관련성을 평가합니다.====\n",
      "\n",
      "LLM 기반의 평가: \n",
      "화 또는 쌀이나 기름 등 현물로 지급하였다고 한다. 2019년 평양\n",
      "의 외화벌이 사업소에서는 보수 50달러를 월 2회로 나누어 현금으\n",
      "로 지급하였다고 하는 사례가 있었고, 평양 외화벌이 식당에서는 매\n",
      " =>점수: 3.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가: \n",
      "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
      "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      " =>점수: 9.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가: \n",
      "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
      "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
      "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
      " =>점수: 6.0\n",
      "\n",
      "\n",
      "LLM 기반의 평가: \n",
      "한 달을 생활하기에 부족한 금액이었다고 하였다. 2018년 양강도의 \n",
      "무역사업소에서는 1년치 노동 보수와 배급을 한 번에 지급하였다고 \n",
      "하는데, 지급된 금액은 노동자 1명에게 1,800위안으로 약 300만원 \n",
      "정도였다고 하였다. 2019년 양강도의 합영회사는 노동자에게 매달 \n",
      "9~12만원의 보수를 지급하고, 1년에 한번 쌀 25kg을 지급하였다는 \n",
      "진술이 있었다. 또한 2020년 합영회사에서는 보수를 성과만큼 받았\n",
      "다고 하는데, 숙련공은 350위안, 쌀 100kg을 살 수 있을 정도의 돈\n",
      "을 받는 경우도 있었다고 하였다.\n",
      " =>점수: 2.0\n",
      "\n",
      "\n",
      "==== LLM의 리랭킹 결과(Top2) ====\n",
      "\n",
      "검색 문서 1:\n",
      "파악되었다. 따라서 기관·기업소의 상황에 따라 식량배급량, 주기, \n",
      "곡식종류에 상당한 차이가 있는 것으로 나타났다. 외화벌이 기관 등\n",
      "에는 식량배급이 원활하게 이뤄지고 있었다는 증언이 수집되었다. \n",
      "2019년 평양시에서 기업소 운전원으로 일하였던 노동자는 매월 쌀·\n",
      "설탕·기름·야채·돼지고기 등을 배급받아 식량이 부족하지 않았다는 \n",
      "증언과 2019년 중앙당 산하의 기업소에서 매월 쌀 6㎏ 정도, 기름 5\n",
      "ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리 정도 받았\n",
      "\n",
      "검색 문서 2:\n",
      "가배급을 선택하고, 잘사는 기업소들은 기업소 자체 배급을 선택합\n",
      "니 다. 세대주가 직장에 다닐 경우 세대주만 직장에서 배급을 받고 \n",
      "가족들은 국가배급소에서 배급을 받습니다. 평양시와 자강도는 대\n",
      "체로 다 줬는데 다른 지역은 배급이 잘 안되고 배급제가 없어졌다는 \n",
      "소리를 들었습니다. ”\n",
      "국가배급의 주기, 양, 곡물의 종류 등에서 평양시와 지방의 차이\n",
      "가 크게 나고 있었다. 식량배급이 비교적 원활하게 작동하는 지역은 \n",
      "평양시로 보이는데, 2017년 어머니가 지역배급 대상자로 배급표가\n",
      "\n",
      "최종 답: 2019년 말 평양시 소재 기업소에서 일하던 노동자는 매월 쌀 6㎏, 기름 5ℓ, 설탕 2㎏, 맛내기 2봉지, 돼지고기 2㎏, 닭고기 1마리를 배급받았습니다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 답변 생성 함수\n",
    "def generate_final_answer(query: str, documents: List[Document]) -> str:\n",
    "  context =\"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "  prompt = f\"\"\" 다음 검색 결과를 바탕으로 질문에 답변해주세요.\n",
    "  검색 결과의 정보를 최대한 사용하고, 없는 정보는 답변하지 마세요.\n",
    "\n",
    "  검색 결과:\n",
    "  {context}\n",
    "\n",
    "  질문: {query}\n",
    "\n",
    "  답변:\"\"\"\n",
    "\n",
    "  response = llm.invoke(prompt)\n",
    "  return response.content\n",
    "\n",
    "# 실제 쿼리 실행\n",
    "query = \"19년 말 평양시 소재 기업소에서 달마다 배급받은 음식\"\n",
    "print(f\"\\n질문: {query}\")\n",
    "\n",
    "# 리래킹을 통해 최적의 문서 2개 선택\n",
    "best_documents = ranker.retrieve(query)\n",
    "\n",
    "# 선택된 문서로 최종 답변 생성\n",
    "final_answer = generate_final_answer(query, best_documents)\n",
    "print(f\"\\n최종 답: {final_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxI4JHSVACN4"
   },
   "source": [
    "generate_final_answer 함수는 검색된 문서들의 내용을 하나의 컨텍스트로 합치고, LLM 에게 이\n",
    "정보만을 사용해서 답변하도록 지시하는 프롬프트를 만듭니다.\n",
    "\n",
    "이후ranker.retrieve() 에실제사용자의질문을입력하면벡터검색, 리랭킹 과정이 순차적으로 이루어져 최적의 2 개 문서가 반환됩니다. 예시로 “19 년 말 평양시 소재 기업소에서 달마다 배급받은 음식”이라는 질문을 ranker.retrieve()로 전달합니다. 이때 내부적으로는 먼저 SemanticRanker가\n",
    "벡터 검색으로 4 개 문서를 찾고 이후 DocumentScorer가 LLM 으로 재평가하여 2 개를 선택한 후,generate_final_answer가 LLM 이 관련성이 가장 높다고 판단한 최종 2 개의 문서들을 바탕으로\n",
    "응답을 생성하여 반환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoUZ6mEQAWAz"
   },
   "source": [
    "먼저 “19 년 말 평양시 소재 기업소에서 달마다 배급받은 음식” 이라는 질문에 대해 벡터 검색이 실행되어 4 개의 문서를 찾아왔습니다. LLM 은 이 4 개 문서를 평가했습니다.\n",
    "-  외화벌이 사업소 보수 관련 문서: 3.0 점\n",
    "-  2019 년 평양시 기업소 구체적 배급량 문서: 9.0 점\n",
    "-  평양시 배급 시스템 일반 설명 문서: 6.0 점\n",
    "-  양강도 합영회사 보수 관련 문서: 1.0 점\n",
    "\n",
    "LLM 이 가장 높은 점수 (9.0) 를 준 문서는 2019 년 평양시 기업소의 구체적인 배급량을 언급한 문서였습\n",
    "니다. 이는 질문이 요구한 시기 (19 년), 장소 (평양시), 대상 (기업소), 내용 (배급받은 음식) 을 모두 정확히 포함하고 있기 때문입니다. 두 번째로 높은 점수 (6.0) 를 받은 문서는 평양시의 배급 시스템에 대한 일반적인 설명이었습니다. 이 문서는 구체적인 배급량을 제시하지는 않지만 평양시 배급 현황에 대한 맥락 정보를 제공하므로 중간 정도의 관련성을 인정받았습니다.\n",
    "\n",
    "반면 양강도 합영회사에 대한 문서는 1.0 점으로 가장 낮은 점수를 받았습니다. 이 문서는 2019 년 정보를\n",
    "포함하고 있지만 평양시가 아닌 양강도에 관한 내용이고, 기업소가 아닌 합영회사에 관한 내용이며, 구체적인 음식 배급보다는 현금 보수와 연간 쌀 지급에 초점을 맞추고 있어 질문과의 관련성이 낮다고 평가되\n",
    "었습니다.\n",
    "\n",
    "최종적으로 점수 순으로 상위 2 개 문서가 선택되어 응답이 생성되었고, 가장 관련성 높은 문서의 구체적\n",
    "인 배급량 정보 (쌀 6kg, 기름 5ℓ, 설탕 2kg, 맛내기 2 봉지, 돼지고기 2kg, 닭고기 1 마리) 를 답변으로 제시\n",
    "했습니다.\n",
    "\n",
    "전체적으로 LLM 리랭킹이 질문의 의도에 적절하게 작동했음을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIHQpr-j7asr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOA4znaEaElzyEiwLBeCNPk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
