{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6V3j2NGwv0a"
   },
   "source": [
    "## 문서를 적재하는 벡터DB\n",
    "앞서 OpenAI의 Embedding API에서는 각 텍스트를 임베딩할 때 파이썬의 Pandas 를\n",
    "이용하여 각 문서와 임베딩을 적재하고, 그 후 Numpy 를 이용하여 코사인 유사도 식을 직접 구현하여 유\n",
    "사도를 구했습니다. 하지만 실제 현업에서는 Pandas 가 아닌 각 문서의 임베딩을 적재하기 위한 용도로\n",
    "특별히 만들어진 도구인 벡터 데이터베이스를 사용하는 경우가 많습니다. 이러한 벡터 데이터베이스로\n",
    "는 Milvus, Faiss, Chroma 등 다양한 데이터베이스가 있지만 여기서는 가장 손쉽게 사용할 수 있는 벡터\n",
    "데이터베이스의 예시로 크로마 (Chroma) 와 파이스 (Faiss) 를 소개합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28341,
     "status": "ok",
     "timestamp": 1753701702327,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "J8o_my4uwuSJ",
    "outputId": "451bd972-d957-445b-a6e0-c44e515fb39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.71)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.35.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.35.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.35.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.56b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.35.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.35.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.35.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.35.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.56b0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=fae69ea4deb8448f815d820e56253893e145cc98099eead66d8ebfb56144219a\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pypdf, pybase64, overrides, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, faiss-cpu, bcrypt, backoff, watchfiles, typing-inspect, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, kubernetes, dataclasses-json, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-community\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 faiss-cpu-1.11.0.post1 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain-community-0.3.27 marshmallow-3.26.1 mmh3-5.1.0 mypy-extensions-1.1.0 onnxruntime-1.22.1 opentelemetry-api-1.35.0 opentelemetry-exporter-otlp-proto-common-1.35.0 opentelemetry-exporter-otlp-proto-grpc-1.35.0 opentelemetry-proto-1.35.0 opentelemetry-sdk-1.35.0 opentelemetry-semantic-conventions-0.56b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pydantic-settings-2.10.1 pypdf-5.9.0 pypika-0.48.9 python-dotenv-1.1.1 typing-inspect-0.9.0 uvloop-0.21.0 watchfiles-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pypdf chromadb faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAHHprVEw90b"
   },
   "source": [
    "###1.크로마\n",
    "OpenAI API 키 값을 세팅하기 위한 os, 파일을 다운로드하기 위한 urllib.request를 임포트하고, 실\n",
    "습을 위해 필요한 랭체인 도구들을 임포트합니다. 앞서 학습했던 PDF 를 로드하는 PyPDFLoader, 문서\n",
    "들을 다수의 청크로 분할하는 RecursiveCharacterTextSplitter, 청크들을 임베딩 벡터로 변\n",
    "환 시 OpenAI 의 Embedding API 를 사용하기 위해 OpenAIEmbeddings, 임베딩 벡터들을 적재하기\n",
    "위한 벡터 데이터베이스인 Chroma와 Faiss를 임포트하고, 사용자의 OpenAI API 키 값을 현재 실습 환\n",
    "경에 세팅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab9yvJtPw9Gy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "os.environ['OPENAI_API_KEY'] = \"Openai_api_key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvZI_rwlxJV7"
   },
   "source": [
    "2023_ 북한인권보고서.pdf 파일을 외부 코드 저장소로부터 다운로드합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769,
     "status": "ok",
     "timestamp": 1753701741260,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "IU83TJGixI3n",
    "outputId": "e5b80723-b2aa-4910-bb61-d79840087a3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2023_북 한 인 권 보 고 서.pdf', <http.client.HTTPMessage at 0x79b16ef39f10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch06/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\", filename=\"2023_북 한 인 권 보 고 서.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7oJMykHxQa3"
   },
   "source": [
    "이제 랭체인의 PyPDFLoader()를 통해 PDF 파일을 로드합니다. PyPDFLoader(파일명)을 실행하\n",
    "여 loader라는 객체를 선언하고, 해당 객체를 통해 load_and_split()을 실행하면 PDF 를 여러 개\n",
    "의 문서 청크로 분할한 문자열 리스트가 반환됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11150,
     "status": "ok",
     "timestamp": 1753701770027,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "9qeT36swxO6s",
    "outputId": "8300bcf2-9d91-47ce-c2a8-215ef108ae13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청 크 의 수: 445\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('2023_북 한 인 권 보 고 서.pdf')\n",
    "pages = loader.load_and_split()\n",
    "print('청 크 의 수:', len(pages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYcKxQzqxVqN"
   },
   "source": [
    "이 청크들을 ChatGPT 와 같은 언어 모델들이 처리할 수 있는 적당한 길이로 추가로 분할해봅시다.\n",
    "RecursiveCharacterTextSplitter()를 이용하여 텍스트를 분할하는 text_splitter 객\n",
    "체를 만듭니다. 이때 chunk_size의 값을 1000 으로 지정하면 앞으로 text_splitter로 텍스트를\n",
    "분할할 때 각 분할된 청크는 길이가 1000 을 넘지 않습니다. chunk_overlap은 텍스트를 분할할 때 각\n",
    "청크가 내용을 얼만큼 겹치게 할 것인지를 정하는 값으로 0 을 사용하면 각 청크의 내용이 겹치지 않습니\n",
    "다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGw5I6vixTZ2"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vfq14hVxavZ"
   },
   "source": [
    "앞서 배운 RecursiveCharacterTextSplitter에서 실습할 때는 파이썬 문자열을\n",
    "분할하기 위해서 create_documents()를 사용했습니다. 하지만 현재는 PyPDFLoader가 로\n",
    "드한 각각의 청크는 파이썬 문자열이 아닌 Document(page_content='내용', metadata={\n",
    "'source': 파일명, 'page': 기존 PDF 파일에서의 페이지 번호})와 같은 형식을 가진 원소\n",
    "입니다. 문자열이 아닌 위와 같은 형식을 가진 청크들을 text_splitter로 분할하는 경우에는\n",
    "split_documents()를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1753701809522,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "jbEm8UnbxZHk",
    "outputId": "5a509a60-b433-4043-bc05-aac23dcd313b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분 할 된 청 크 의 수: 496\n"
     ]
    }
   ],
   "source": [
    "splitted_docs = text_splitter.split_documents(pages)\n",
    "print('분 할 된 청 크 의 수:', len(splitted_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLUNmoIbxh_g"
   },
   "source": [
    "청크의 수가 445 개에서 496 개로 더 늘어났습니다. 실제로 각 청크의 길이를 재보면 1,000 이 넘지 않는것을 확인할 수 있습니다. 496 개의 청크들에 대해 가장 긴 청크의 길이, 가장 짧은 청크의 길이, 청크들의\n",
    "평균 길이를 구해봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1753701857364,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "NwcilaWxxfw0",
    "outputId": "27bc455e-6952-419c-9636-6ba3ad27fd93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청 크 의 최 대 길 이 : 1000\n",
      "청 크 의 최 소 길 이 : 6\n",
      "청 크 의 평 균 길 이 : 750.2983870967741\n"
     ]
    }
   ],
   "source": [
    "chunks = [splitted_doc.page_content for splitted_doc in splitted_docs]\n",
    "print('청 크 의 최 대 길 이 :',max(len(chunk) for chunk in chunks))\n",
    "print('청 크 의 최 소 길 이 :',min(len(chunk) for chunk in chunks))\n",
    "print('청 크 의 평 균 길 이 :',sum(map(len, chunks))/len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9w0GVXsxtmT"
   },
   "source": [
    "이제 496 개의 청크를 모두 OpenAI 의 Embedding API 로 임베딩하여 크로마 데이터베이스에 적재해봅\n",
    "시다. 각 청크를 임베딩과 동시에 크로마 데이터베이스에 적재할 때는 Chroma.from_documents(\n",
    "청크들의 리스트, OpenAIEmbeddings())를 사용합니다. 뒤에서 실습할 파이스 벡터 데이터베이\n",
    "스도 코드 형식이 거의 동일하므로 기억해둡시다. Chroma.from_documents()를 통해 벡터 데이터\n",
    "베이스 객체를 만들고 나서 적재된 문서의 수를 출력하는 것은 _collection.count()를 통해 가능\n",
    "합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10692,
     "status": "ok",
     "timestamp": 1753701900110,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "wlPa387cxrcu",
    "outputId": "bc199e7d-360b-484e-f85c-f804695f78d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-8-3301462923.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  db = Chroma.from_documents(splitted_docs, OpenAIEmbeddings(chunk_size=100))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 서 의 수: 496\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(splitted_docs, OpenAIEmbeddings(chunk_size=100))\n",
    "print('문 서 의 수:', db._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhkQM37bxx_H"
   },
   "source": [
    "데이터 베이스 객체를 만들고 나서 사용자의 입력과 유사도가 높은 문서들을 찾을때는\n",
    "similarity_search(사용자의 입력)을 사용 합니다. 북 한인권보고서라는 PDF 파일이므로 ‘북한의 교육 과정’ 이라는 질의를 입력하여 연관 청크들을 찾아봅시다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1753702119940,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "vKz_sTY7x2LX",
    "outputId": "3733ad01-c298-4775-921d-e7541d17346d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 서 의 수: 4\n"
     ]
    }
   ],
   "source": [
    "question = '북한의 교육 과정'\n",
    "docs = db.similarity_search(question)\n",
    "print('문 서 의 수:', len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHocxv3hyFls"
   },
   "source": [
    "연관 청크를 4 개 찾습니다. 실제로 출력하여 ‘북한의 교육 과정’ 과 연관된 문서인지 확인해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1753702123560,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "Cf8kl_cnyDzc",
    "outputId": "af009b8a-aadd-4248-fd34-5e698332083e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2023 북한인권보고서\n",
      "40\n",
      "명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\n",
      "서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\n",
      "과서가 모든 학생에게 충분히 제공되지 않고 학년을 마치면 다음 학\n",
      "년에 교과서를 물려주어야 했다는 사례가 다수 수집되었다. 소학교\n",
      "부터 학교운영비, 꼬마계획 등의 비용을 내야했다는 진술이 꾸준히 \n",
      "수집되고 있는데, 학교시설 현대화 작업이 진행되면서 학교꾸리기 \n",
      "비용이 증가했다고 한다. 학교에서 요구하는 돈이나 물품은 교원에 \n",
      "의해 사실상 강제되고 있었는데, 비용을 내지 못하는 경우 동급생들 \n",
      "앞에서 망신을 주거나 비판하여 형편이 어려운 학생들은 학교를 그\n",
      "만두는 선택을 하는 경우가 많다고 한다. 또한 도시와 농촌 간 교육\n",
      "환경의 차이가 크며 대학입학에서 출신성분에 의한 차별이 있고, 교\n",
      "육기회의 제공에도 경제력이 영향을 미치고 있어 성분·지역·경제\n",
      "력에 따른 차별이 존재하는 것으로 나타났다. 교육환경도 열악한데, \n",
      "학교시설의 현대화 작업에도 불구하고 양호실, 도서관, 위생시설이 \n",
      "없는 학교도 많은 것으로 보인다. 교원에 대한 경제적 보상도 적절\n",
      "히 이루어지지 않아, 교원들은 생계를 유지하기 위해 잘사는 학부모\n",
      "의 원조를 받거나 자신의 텃밭에 학생을 동원시키고 있어 학생들은 \n",
      "제대로 된 교육여건을 보장받지 못하고 있는 것으로 나타났다. 또\n",
      "한, 일반교육보다 정치사상교육을 앞세우고 있으며 교과과정에 실\n",
      "탄사격을 하는 군사훈련을 편성하여 학생들을 의무적으로 참석하게 \n",
      "하고 있다.\n",
      "북한의 사회보장 제도로는 연로연금, 노동능력상실 연금, 유가족 \n",
      "연금 등 생계가 결핍된 경우 기초적인 생계를 보장하기 위한 연금제\n",
      "도가 있으며, 사회보험금의 성격을 지닌 보조금 제도가 있다. 연로' metadata={'moddate': '2023-07-31T13:57:54+09:00', 'producer': 'Adobe PDF Library 10.0.1', 'creationdate': '2023-07-31T13:50:27+09:00', 'source': '2023_북 한 인 권 보 고 서.pdf', 'page': 41, 'trapped': '/False', 'total_pages': 448, 'creator': 'Adobe InDesign CS6 (Windows)', 'page_label': '42'}\n",
      "--------------------\n",
      "page_content='309\t\t북한의\t학제는\t2012년\t전반적\t의무교육(유치원\t1년,\t소학교\t5년,\t초급중학교\t3년,\t고급중학교\t3년)으로\t\n",
      "개편되었는데,\t학제개편\t이전에는\t초급중학교와\t고급중학교를\t통합하여\t중학교\t6년\t과정(1972년~2011\n",
      "년)으로\t운영하였고,\t중학교\t또는\t고등중학교라고\t칭하였다.(통일부\t국립통일교육원,\t『북한의\t이해』,\t\n",
      "2022)' metadata={'page': 283, 'moddate': '2023-07-31T13:57:54+09:00', 'total_pages': 448, 'trapped': '/False', 'page_label': '284', 'creator': 'Adobe InDesign CS6 (Windows)', 'producer': 'Adobe PDF Library 10.0.1', 'source': '2023_북 한 인 권 보 고 서.pdf', 'creationdate': '2023-07-31T13:50:27+09:00'}\n",
      "--------------------\n",
      "page_content='2023 북한인권보고서\n",
      "184\n",
      "데, 당국이 실시하는 반종교 교육을 통해 기독교를 접한 경우였다. 기\n",
      "독교 관련 북한당국의 반종교 교육은 학교 교과과정에서 뿐만 아니\n",
      "라 졸업 후 조직생활을 통해서도 이루어지고 있었다. 수집된 증언에 \n",
      "따르면 북한에서 반종교 교육을 받고 종교에 대한 부정적 인식이 증\n",
      "가했다고 한다. 기독교를 믿는 사람을 반동분자로 인식하고 있었다\n",
      "는 증언들도 있었다. 한 증언자는 2015년에 계급교양관을 1달에 1번\n",
      "씩 참관해야 했는데, 거기서 ‘종교는 침략자들이 북한에 가져온 것으\n",
      "로 그들이 성경도 가져왔다’는 내용이 포함된 반종교 교육을 받았다\n",
      "고 한다. 기독교인들은 제국주의적 침략의 앞잡이이므로 반민족적·\n",
      "반혁명적 적대계층이라는 내용도 있었다고 한다. 다른 증언자는 교육\n",
      "기관, 사회기관, 법기관에서 ‘종교는 허황된 것이고 거짓’이며 선교사\n",
      "는 악한 자라고 세뇌가 될 정도로 지속적으로 교육하기 때문에 감히 \n",
      "종교에 관심을 가질 생각도 하지 못했고 ‘선교사’라는 단어를 들으면 \n",
      "지금도 무섭다고 한다. 인민반 강연 등에서 기독교를 믿는 사람은 반\n",
      "동분자라고 하면서 이들을 보면 신고하라고 했다는 증언도 있었다. \n",
      "“주민들을 모아 놓고 교양하는 때가 있었는데, 그 때 처음 ‘성경책 \n",
      "사진, 예배하는 모습의 사진’을 본 적이 있습니다. 반동조직이라고 \n",
      "교육하면서 성경에는 미신에 관한 것이 적혀있어 이것을 읽게 되면 \n",
      "사상이 변질되니 이런 책을 주변에서 보게 되면 신고하라고 했습니\n",
      "다. 이들은 국가 반역자로 이 땅에서 사라져야 한다고 선전했습니\n",
      "다. 그래서 재북시 저 뿐만이 아니라 북한 주민들은 성경책이 북한 \n",
      "제도에 대해 안 좋게 적어놓은 책으로 알고 있었고 이를 소지하면 \n",
      "죽임을 당한다고 알고 있었습니다. ”\n",
      "북한에서 기독교를 탄압하는 이유는 기독교의 유일신 사상이 수\n",
      "령 우상화 정책과 주체사상에 반하기 때문이라고 한다. 한 증언자는' metadata={'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-07-31T13:50:27+09:00', 'source': '2023_북 한 인 권 보 고 서.pdf', 'total_pages': 448, 'page_label': '186', 'trapped': '/False', 'producer': 'Adobe PDF Library 10.0.1', 'moddate': '2023-07-31T13:57:54+09:00', 'page': 185}\n",
      "--------------------\n",
      "page_content='2023 북한인권보고서\n",
      "342\n",
      "2018년에 학교에서 추천하여 소년궁전 스키부에 선발되었으나, 체\n",
      "육종합지도원이 자신의 출신성분이 좋지 않다는 이유로 선발명단에\n",
      "서 자신을 제외했다고 진술하였다. 정치범수용소에서는 이주민 자\n",
      "녀의 경우 정규교육과정을 받지 못한다는 증언도 있었다. 정치범수\n",
      "용소에도 소학교와 중학교가 있지만 일반 학교와는 달리 학생들이 \n",
      "책가방 대신 지게를 지고 출석하고 학교에서 농사짓는 법에 대해 배\n",
      "운다고 한다. \n",
      "북한에서는 대학 진학 시에도 출신성분에 따른 차별이 존재하는 \n",
      "것으로 나타났다. 한 증언자는 2019년에 고급중학교를 졸업하고 대\n",
      "학에 진학하려고 했는데, 본인 문건에 어머니가 행방불명으로 되어 \n",
      "있어 출신성분이 나쁘다는 이유로 대학에 진학할 수 없었다고 한다. \n",
      "이러한 차별행위는 교육부의 정책에 따른 것이라고 한다. 다른 증\n",
      "언자는 2018년에 의학대학에 진학하고 싶었는데, 교육과장과 면담\n",
      "하는 과정에서 ‘어머니가 행방불명이라 너 같은 아이는 대학에 가기 \n",
      "어렵다.’는 이야기를 듣고 대학 진학을 포기했다고 한다. 중학교 졸\n",
      "업 후 농민의 자식이라는 이유로 일반 대학뿐만 아니라 공업전문학\n",
      "교도 진학할 수 없었다는 증언도 있었다. \n",
      " \n",
      "(2) 경제력에 따른 차별 \n",
      "북한에서는 교육기회에 있어 경제력에 따른 차별이 존재하는 것\n",
      "으로 보인다. 수집된 증언에 따르면 무상교육제가 유명무실해진 상\n",
      "황에서 교육비 부담으로 경제적 취약계층의 아동들이 장기간 결석하\n",
      "거나 중도에 학교를 그만두는 것으로 나타났다. 한 증언자는 2018년\n",
      "에 아들이 소학교 학생이었는데, 당시 학급 정원의 25% 정도가 경제' metadata={'trapped': '/False', 'source': '2023_북 한 인 권 보 고 서.pdf', 'page': 343, 'total_pages': 448, 'producer': 'Adobe PDF Library 10.0.1', 'moddate': '2023-07-31T13:57:54+09:00', 'creator': 'Adobe InDesign CS6 (Windows)', 'page_label': '344', 'creationdate': '2023-07-31T13:50:27+09:00'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc)\n",
    "    print('--' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhIXz1GDyap_"
   },
   "source": [
    "북한의 교육과 관련된 문서 4 개가 출력된 것을 확인할 수 있습니다. 크로마 벡터 데이터베이스를 파일\n",
    "로 저장하는 것도 가능합니다. Chroma.from_documents()에서 persist_directory='디렉\n",
    "터리명'을 사용합니다. 다음 코드를 수행하면 실제로 코드 실행 경로에 ‘ chroma_test.db’라는 디\n",
    "렉터리가 생깁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8136,
     "status": "ok",
     "timestamp": 1753702147908,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "7_Wb9p_RyHeZ",
    "outputId": "6f463353-8cf9-42c5-ba33-0f57140951a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 서 의 수: 992\n"
     ]
    }
   ],
   "source": [
    "db_to_file = Chroma.from_documents(splitted_docs, OpenAIEmbeddings(chunk_size=100),\n",
    "                                   persist_directory = './chroma_test.db')\n",
    "print('문 서 의 수:', db_to_file._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq3uhYkUygxc"
   },
   "source": [
    "저장한 데이터베이스 파일을 로드해서 사용해봅시다. 로드는 Chroma(persist_directory='디\n",
    "렉터리명', embedding_function=사용하고 있는 임베딩))으로 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1753702150986,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "z7-gVJfzyelM",
    "outputId": "5be4808b-80a2-4a6e-841d-6d81bdc1fd23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 서 의 수: 992\n"
     ]
    }
   ],
   "source": [
    "db_from_file = Chroma(persist_directory='./chroma_test.db',\n",
    "                      embedding_function=OpenAIEmbeddings())\n",
    "print('문 서 의 수:', db_from_file._collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2pJ9_0NymiP"
   },
   "source": [
    "앞서 similarity_search(사용자의 입력)을 사용했을 때는 사용자의 입력에 대해 유사한 청크 4\n",
    "개를 찾아냈습니다. 내부적으로는 유사도를 구하고 유사도 점수 상위 4 개의 청크를 찾아낸 것입니다.\n",
    "이번에는 유사한 청크를 상위 3 개만 찾도록 강제하고, 유사도 점수 또한 출력하도록 해보겠습니다.\n",
    "그러려면 similarity_search_with_relevance_scores(사용자의 입력, k=찾고자 하는\n",
    "문서의 수)와 같이 하면 됩니다. 유사한 청크를 상위 3 개만 찾도록 강제하기 위해 k 의 값을 3 으로 지\n",
    "정했고 유사도 점수 상위 3 개의 청크를 찾아서 출력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1753702175471,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "DO-nAnUvyksX",
    "outputId": "2704b0b0-292f-4333-ae93-c64ec57dcff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(metadata={'total_pages': 448, 'page': 41, 'creationdate': '2023-07-31T13:50:27+09:00', 'creator': 'Adobe InDesign CS6 (Windows)', 'producer': 'Adobe PDF Library 10.0.1', 'page_label': '42', 'source': '2023_북 한 인 권 보 고 서.pdf', 'moddate': '2023-07-31T13:57:54+09:00', 'trapped': '/False'}, page_content='2023 북한인권보고서\\n40\\n명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\\n서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\\n과서가 모든 학생에게 충분히 제공되지 않고 학년을 마치면 다음 학\\n년에 교과서를 물려주어야 했다는 사례가 다수 수집되었다. 소학교\\n부터 학교운영비, 꼬마계획 등의 비용을 내야했다는 진술이 꾸준히 \\n수집되고 있는데, 학교시설 현대화 작업이 진행되면서 학교꾸리기 \\n비용이 증가했다고 한다. 학교에서 요구하는 돈이나 물품은 교원에 \\n의해 사실상 강제되고 있었는데, 비용을 내지 못하는 경우 동급생들 \\n앞에서 망신을 주거나 비판하여 형편이 어려운 학생들은 학교를 그\\n만두는 선택을 하는 경우가 많다고 한다. 또한 도시와 농촌 간 교육\\n환경의 차이가 크며 대학입학에서 출신성분에 의한 차별이 있고, 교\\n육기회의 제공에도 경제력이 영향을 미치고 있어 성분·지역·경제\\n력에 따른 차별이 존재하는 것으로 나타났다. 교육환경도 열악한데, \\n학교시설의 현대화 작업에도 불구하고 양호실, 도서관, 위생시설이 \\n없는 학교도 많은 것으로 보인다. 교원에 대한 경제적 보상도 적절\\n히 이루어지지 않아, 교원들은 생계를 유지하기 위해 잘사는 학부모\\n의 원조를 받거나 자신의 텃밭에 학생을 동원시키고 있어 학생들은 \\n제대로 된 교육여건을 보장받지 못하고 있는 것으로 나타났다. 또\\n한, 일반교육보다 정치사상교육을 앞세우고 있으며 교과과정에 실\\n탄사격을 하는 군사훈련을 편성하여 학생들을 의무적으로 참석하게 \\n하고 있다.\\n북한의 사회보장 제도로는 연로연금, 노동능력상실 연금, 유가족 \\n연금 등 생계가 결핍된 경우 기초적인 생계를 보장하기 위한 연금제\\n도가 있으며, 사회보험금의 성격을 지닌 보조금 제도가 있다. 연로'), 0.8285190772921812)\n",
      "--------------------\n",
      "(Document(metadata={'trapped': '/False', 'creationdate': '2023-07-31T13:50:27+09:00', 'source': '2023_북 한 인 권 보 고 서.pdf', 'producer': 'Adobe PDF Library 10.0.1', 'page_label': '42', 'page': 41, 'moddate': '2023-07-31T13:57:54+09:00', 'creator': 'Adobe InDesign CS6 (Windows)', 'total_pages': 448}, page_content='2023 북한인권보고서\\n40\\n명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\\n서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\\n과서가 모든 학생에게 충분히 제공되지 않고 학년을 마치면 다음 학\\n년에 교과서를 물려주어야 했다는 사례가 다수 수집되었다. 소학교\\n부터 학교운영비, 꼬마계획 등의 비용을 내야했다는 진술이 꾸준히 \\n수집되고 있는데, 학교시설 현대화 작업이 진행되면서 학교꾸리기 \\n비용이 증가했다고 한다. 학교에서 요구하는 돈이나 물품은 교원에 \\n의해 사실상 강제되고 있었는데, 비용을 내지 못하는 경우 동급생들 \\n앞에서 망신을 주거나 비판하여 형편이 어려운 학생들은 학교를 그\\n만두는 선택을 하는 경우가 많다고 한다. 또한 도시와 농촌 간 교육\\n환경의 차이가 크며 대학입학에서 출신성분에 의한 차별이 있고, 교\\n육기회의 제공에도 경제력이 영향을 미치고 있어 성분·지역·경제\\n력에 따른 차별이 존재하는 것으로 나타났다. 교육환경도 열악한데, \\n학교시설의 현대화 작업에도 불구하고 양호실, 도서관, 위생시설이 \\n없는 학교도 많은 것으로 보인다. 교원에 대한 경제적 보상도 적절\\n히 이루어지지 않아, 교원들은 생계를 유지하기 위해 잘사는 학부모\\n의 원조를 받거나 자신의 텃밭에 학생을 동원시키고 있어 학생들은 \\n제대로 된 교육여건을 보장받지 못하고 있는 것으로 나타났다. 또\\n한, 일반교육보다 정치사상교육을 앞세우고 있으며 교과과정에 실\\n탄사격을 하는 군사훈련을 편성하여 학생들을 의무적으로 참석하게 \\n하고 있다.\\n북한의 사회보장 제도로는 연로연금, 노동능력상실 연금, 유가족 \\n연금 등 생계가 결핍된 경우 기초적인 생계를 보장하기 위한 연금제\\n도가 있으며, 사회보험금의 성격을 지닌 보조금 제도가 있다. 연로'), 0.8284798069660813)\n",
      "--------------------\n",
      "(Document(metadata={'trapped': '/False', 'producer': 'Adobe PDF Library 10.0.1', 'total_pages': 448, 'creator': 'Adobe InDesign CS6 (Windows)', 'page': 283, 'creationdate': '2023-07-31T13:50:27+09:00', 'moddate': '2023-07-31T13:57:54+09:00', 'source': '2023_북 한 인 권 보 고 서.pdf', 'page_label': '284'}, page_content='309\\t\\t북한의\\t학제는\\t2012년\\t전반적\\t의무교육(유치원\\t1년,\\t소학교\\t5년,\\t초급중학교\\t3년,\\t고급중학교\\t3년)으로\\t\\n개편되었는데,\\t학제개편\\t이전에는\\t초급중학교와\\t고급중학교를\\t통합하여\\t중학교\\t6년\\t과정(1972년~2011\\n년)으로\\t운영하였고,\\t중학교\\t또는\\t고등중학교라고\\t칭하였다.(통일부\\t국립통일교육원,\\t『북한의\\t이해』,\\t\\n2022)'), 0.8282070536359429)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "question = '북한의 교육 과정'\n",
    "top_three_docs = db_from_file.similarity_search_with_relevance_scores(question, k=3)\n",
    "for doc in top_three_docs:\n",
    "  print(doc)\n",
    "  print('--' * 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHglA1g3y6wa"
   },
   "source": [
    "###2. 파이스\n",
    "이번에는 크로마 외에 랭체인에서 제공하는 또 다른 벡터 데이터베이스인 파이스를 사용해봅시\n",
    "다. 앞서 만든 497 개의 청크들을 모두 OpenAI 의 Embedding API 로 임베딩하여 파이스 데이터베\n",
    "이스에 적재해봅시다. 각 청크를 임베딩과 동시에 크로마 데이터베이스에 적재할 때는 FAISS.\n",
    "from_documents(청크들의 리스트, OpenAIEmbeddings())를 사용하여 파이스 벡터 데이터\n",
    "베이스 객체인 faiss_db를 만듭니다. 크로마 벡터 데이터베이스를 사용할 때의 코드가 Chroma.\n",
    "from_documents(청크들의 리스트, OpenAIEmbeddings())였던 것과 매우 유사합니다. 하\n",
    "지만 그 외 문서의 수를 확인하는 것, 파일을 저장하고 로드하는 등의 일부 코드는 상이하므로 주의합니\n",
    "다. 예를 들어 파이스의 경우, 저장된 청크의 수를 확인하고자 할 때는 index.ntotal을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6632,
     "status": "ok",
     "timestamp": 1753702234267,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "0pMNMFhmy3Dh",
    "outputId": "1f343206-dce3-4f70-88e1-5cc57df004c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문 서 의 수: 496\n"
     ]
    }
   ],
   "source": [
    "faiss_db = FAISS.from_documents(splitted_docs, OpenAIEmbeddings(chunk_size=100))\n",
    "print('문 서 의 수:', faiss_db.index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGV391ZKzInE"
   },
   "source": [
    "파이스 벡터 데이터베이스를 파일로 저장하는 것도 가능합니다. 이를 위해서는 faiss_db.\n",
    "save_local(디렉터리명)을 사 용 합 니 다. 다 음 코 드 를 수 행 하 면 실 제 로 코 드 실 행 경 로 에 ‘\n",
    "faiss_index’라는 디렉터리가 생깁니다. 반대로 FAISS 의 load_local(디렉터리명)을 사용하\n",
    "여 저장한 벡터 데이터베이스를 로드할 수 있습니다. 이때 사용한 임베딩을 인자로 알려줘야 하므로\n",
    "OpenAIEmbeddings()를 전달합니다. allow_dangerous_deserialization은 파이썬 객체\n",
    "를 저장하거나 전송할 때 사용하는 파일을 읽을 때 일부 파일에 보안 위험이 있을 경우 읽는 것이 거부당\n",
    "하는 경우가 있는데, 에러를 발생시키지 않고 해당 파일을 신뢰할 수 있으니 무시하고 읽겠다는 의미입니\n",
    "다. 해당 파일은 방금 전에 사용자가 저장한 것이므로 무시하고 읽도록 True로 설정합니다. 파일을 다시\n",
    "읽어서 new_db_faiss라는 벡터 데이터베이스 객체에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VURM1zezBWM"
   },
   "outputs": [],
   "source": [
    "faiss_db.save_local('faiss_index')\n",
    "\n",
    "new_db_faiss = FAISS.load_local('faiss_index',\n",
    "                                OpenAIEmbeddings(),\n",
    "                                allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2QLEw5czUaH"
   },
   "source": [
    "크로마와 마찬가지로 ‘북한의 교육과정’ 으로 검색하여 연관된 문서를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1753702313078,
     "user": {
      "displayName": "유진철",
      "userId": "18428759730043573350"
     },
     "user_tz": -540
    },
    "id": "D7x8n_8dzS2p",
    "outputId": "949d06f8-7e0c-428c-a9ad-c7448dd7c8dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='2023 북한인권보고서\n",
      "40\n",
      "명목의 교육비용이 전가되고 있는 것으로 나타났다. 교과서는 ‘교과\n",
      "서 요금’이라는 명목으로 일정 금액을 내야하는 경우가 많으며, 교\n",
      "과서가 모든 학생에게 충분히 제공되지 않고 학년을 마치면 다음 학\n",
      "년에 교과서를 물려주어야 했다는 사례가 다수 수집되었다. 소학교\n",
      "부터 학교운영비, 꼬마계획 등의 비용을 내야했다는 진술이 꾸준히 \n",
      "수집되고 있는데, 학교시설 현대화 작업이 진행되면서 학교꾸리기 \n",
      "비용이 증가했다고 한다. 학교에서 요구하는 돈이나 물품은 교원에 \n",
      "의해 사실상 강제되고 있었는데, 비용을 내지 못하는 경우 동급생들 \n",
      "앞에서 망신을 주거나 비판하여 형편이 어려운 학생들은 학교를 그\n",
      "만두는 선택을 하는 경우가 많다고 한다. 또한 도시와 농촌 간 교육\n",
      "환경의 차이가 크며 대학입학에서 출신성분에 의한 차별이 있고, 교\n",
      "육기회의 제공에도 경제력이 영향을 미치고 있어 성분·지역·경제\n",
      "력에 따른 차별이 존재하는 것으로 나타났다. 교육환경도 열악한데, \n",
      "학교시설의 현대화 작업에도 불구하고 양호실, 도서관, 위생시설이 \n",
      "없는 학교도 많은 것으로 보인다. 교원에 대한 경제적 보상도 적절\n",
      "히 이루어지지 않아, 교원들은 생계를 유지하기 위해 잘사는 학부모\n",
      "의 원조를 받거나 자신의 텃밭에 학생을 동원시키고 있어 학생들은 \n",
      "제대로 된 교육여건을 보장받지 못하고 있는 것으로 나타났다. 또\n",
      "한, 일반교육보다 정치사상교육을 앞세우고 있으며 교과과정에 실\n",
      "탄사격을 하는 군사훈련을 편성하여 학생들을 의무적으로 참석하게 \n",
      "하고 있다.\n",
      "북한의 사회보장 제도로는 연로연금, 노동능력상실 연금, 유가족 \n",
      "연금 등 생계가 결핍된 경우 기초적인 생계를 보장하기 위한 연금제\n",
      "도가 있으며, 사회보험금의 성격을 지닌 보조금 제도가 있다. 연로' metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-07-31T13:50:27+09:00', 'moddate': '2023-07-31T13:57:54+09:00', 'trapped': '/False', 'source': '2023_북 한 인 권 보 고 서.pdf', 'total_pages': 448, 'page': 41, 'page_label': '42'}\n",
      "--------------------\n",
      "page_content='309\t\t북한의\t학제는\t2012년\t전반적\t의무교육(유치원\t1년,\t소학교\t5년,\t초급중학교\t3년,\t고급중학교\t3년)으로\t\n",
      "개편되었는데,\t학제개편\t이전에는\t초급중학교와\t고급중학교를\t통합하여\t중학교\t6년\t과정(1972년~2011\n",
      "년)으로\t운영하였고,\t중학교\t또는\t고등중학교라고\t칭하였다.(통일부\t국립통일교육원,\t『북한의\t이해』,\t\n",
      "2022)' metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-07-31T13:50:27+09:00', 'moddate': '2023-07-31T13:57:54+09:00', 'trapped': '/False', 'source': '2023_북 한 인 권 보 고 서.pdf', 'total_pages': 448, 'page': 283, 'page_label': '284'}\n",
      "--------------------\n",
      "page_content='2023 북한인권보고서\n",
      "184\n",
      "데, 당국이 실시하는 반종교 교육을 통해 기독교를 접한 경우였다. 기\n",
      "독교 관련 북한당국의 반종교 교육은 학교 교과과정에서 뿐만 아니\n",
      "라 졸업 후 조직생활을 통해서도 이루어지고 있었다. 수집된 증언에 \n",
      "따르면 북한에서 반종교 교육을 받고 종교에 대한 부정적 인식이 증\n",
      "가했다고 한다. 기독교를 믿는 사람을 반동분자로 인식하고 있었다\n",
      "는 증언들도 있었다. 한 증언자는 2015년에 계급교양관을 1달에 1번\n",
      "씩 참관해야 했는데, 거기서 ‘종교는 침략자들이 북한에 가져온 것으\n",
      "로 그들이 성경도 가져왔다’는 내용이 포함된 반종교 교육을 받았다\n",
      "고 한다. 기독교인들은 제국주의적 침략의 앞잡이이므로 반민족적·\n",
      "반혁명적 적대계층이라는 내용도 있었다고 한다. 다른 증언자는 교육\n",
      "기관, 사회기관, 법기관에서 ‘종교는 허황된 것이고 거짓’이며 선교사\n",
      "는 악한 자라고 세뇌가 될 정도로 지속적으로 교육하기 때문에 감히 \n",
      "종교에 관심을 가질 생각도 하지 못했고 ‘선교사’라는 단어를 들으면 \n",
      "지금도 무섭다고 한다. 인민반 강연 등에서 기독교를 믿는 사람은 반\n",
      "동분자라고 하면서 이들을 보면 신고하라고 했다는 증언도 있었다. \n",
      "“주민들을 모아 놓고 교양하는 때가 있었는데, 그 때 처음 ‘성경책 \n",
      "사진, 예배하는 모습의 사진’을 본 적이 있습니다. 반동조직이라고 \n",
      "교육하면서 성경에는 미신에 관한 것이 적혀있어 이것을 읽게 되면 \n",
      "사상이 변질되니 이런 책을 주변에서 보게 되면 신고하라고 했습니\n",
      "다. 이들은 국가 반역자로 이 땅에서 사라져야 한다고 선전했습니\n",
      "다. 그래서 재북시 저 뿐만이 아니라 북한 주민들은 성경책이 북한 \n",
      "제도에 대해 안 좋게 적어놓은 책으로 알고 있었고 이를 소지하면 \n",
      "죽임을 당한다고 알고 있었습니다. ”\n",
      "북한에서 기독교를 탄압하는 이유는 기독교의 유일신 사상이 수\n",
      "령 우상화 정책과 주체사상에 반하기 때문이라고 한다. 한 증언자는' metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-07-31T13:50:27+09:00', 'moddate': '2023-07-31T13:57:54+09:00', 'trapped': '/False', 'source': '2023_북 한 인 권 보 고 서.pdf', 'total_pages': 448, 'page': 185, 'page_label': '186'}\n",
      "--------------------\n",
      "page_content='2023 북한인권보고서\n",
      "342\n",
      "2018년에 학교에서 추천하여 소년궁전 스키부에 선발되었으나, 체\n",
      "육종합지도원이 자신의 출신성분이 좋지 않다는 이유로 선발명단에\n",
      "서 자신을 제외했다고 진술하였다. 정치범수용소에서는 이주민 자\n",
      "녀의 경우 정규교육과정을 받지 못한다는 증언도 있었다. 정치범수\n",
      "용소에도 소학교와 중학교가 있지만 일반 학교와는 달리 학생들이 \n",
      "책가방 대신 지게를 지고 출석하고 학교에서 농사짓는 법에 대해 배\n",
      "운다고 한다. \n",
      "북한에서는 대학 진학 시에도 출신성분에 따른 차별이 존재하는 \n",
      "것으로 나타났다. 한 증언자는 2019년에 고급중학교를 졸업하고 대\n",
      "학에 진학하려고 했는데, 본인 문건에 어머니가 행방불명으로 되어 \n",
      "있어 출신성분이 나쁘다는 이유로 대학에 진학할 수 없었다고 한다. \n",
      "이러한 차별행위는 교육부의 정책에 따른 것이라고 한다. 다른 증\n",
      "언자는 2018년에 의학대학에 진학하고 싶었는데, 교육과장과 면담\n",
      "하는 과정에서 ‘어머니가 행방불명이라 너 같은 아이는 대학에 가기 \n",
      "어렵다.’는 이야기를 듣고 대학 진학을 포기했다고 한다. 중학교 졸\n",
      "업 후 농민의 자식이라는 이유로 일반 대학뿐만 아니라 공업전문학\n",
      "교도 진학할 수 없었다는 증언도 있었다. \n",
      " \n",
      "(2) 경제력에 따른 차별 \n",
      "북한에서는 교육기회에 있어 경제력에 따른 차별이 존재하는 것\n",
      "으로 보인다. 수집된 증언에 따르면 무상교육제가 유명무실해진 상\n",
      "황에서 교육비 부담으로 경제적 취약계층의 아동들이 장기간 결석하\n",
      "거나 중도에 학교를 그만두는 것으로 나타났다. 한 증언자는 2018년\n",
      "에 아들이 소학교 학생이었는데, 당시 학급 정원의 25% 정도가 경제' metadata={'producer': 'Adobe PDF Library 10.0.1', 'creator': 'Adobe InDesign CS6 (Windows)', 'creationdate': '2023-07-31T13:50:27+09:00', 'moddate': '2023-07-31T13:57:54+09:00', 'trapped': '/False', 'source': '2023_북 한 인 권 보 고 서.pdf', 'total_pages': 448, 'page': 343, 'page_label': '344'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "question = '북한의 교육 과정'\n",
    "docs = new_db_faiss.similarity_search(question)\n",
    "for doc in docs:\n",
    "  print(doc)\n",
    "  print('--' * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Y7MirnAzeYY"
   },
   "source": [
    "보다시피 크로마와 동일한 결과를 얻었습니다. 이렇게 해서 이번 장에서는 랭체인 기초, 텍스트를 청크로\n",
    "분할하는 방법, 청크를 임베딩 벡터로 변환하고 적재한 후에 사용자의 입력과 유사한 청크를 찾게 도와주\n",
    "는 벡터 데이터베이스에 대해 알아봤습니다. 앞으로 이어지는 실습에서는 지금까지 랭체인의 다양한 도\n",
    "구를 이용하여 지금까지보다 더욱 난이도가 높은 AI 서비스들을 개발해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3sMmZtbzamb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMjHCHGVXx3ZWy2/IJ5YoU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
