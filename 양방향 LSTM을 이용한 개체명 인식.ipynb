{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOqs4zeST0ABhluN8n/F0y7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 양방향 LSTM을 이용한 개체명 인식\n","PyTorch의 양방향 LSTM(Bidirectional LSTM)을 이용하여 개체명 인식 모델을 구현해보겠습니다.\n","\n","코퍼스로부터 각 개체(entity)의 유형을 인식하는 개체명 인식(Named Entity Recognition)에 대해서 학습합니다. 개체명 인식을 사용하면 코퍼스로부터 어떤 단어가 사람, 장소, 조직 등을 의미하는 단어인지를 찾을 수 있습니다."],"metadata":{"id":"6QSQyqcNgYNU"}},{"cell_type":"markdown","source":["###1. 개체명 인식(Name Entity Recognition)이란\n","\n","개체명 인식(Named Entity Recognition)이란 말 그대로 이름을 가진 개체(named entity)를 인식하겠다는 것을 의미합니다. 좀 더 쉽게 설명하면, 어떤 이름을 의미하는 단어를 보고는 그 단어가 어떤 유형인지를 인식하는 것을 말합니다.\n","\n","예를 들어 유정이는 2018년에 골드만삭스에 입사했다. 라는 문장이 있을 때, 사람(person), 조직(organization), 시간(time)에 대해 개체명 인식을 수행하는 모델이라면 다음과 같은 결과를 보여줍니다\n"],"metadata":{"id":"WlWNAZuogjE1"}},{"cell_type":"markdown","source":["### 2. NLTK를 이용한 개체명 인식(Namee Entity Recognition using NLTK)\n","NLTK에서는 개체명 인식기(NER chunker)를 지원하고 있으므로, 별도 개체명 인식기를 구현할 필요없이 NLTK를 사용해서 개체명 인식을 수행할 수 있습니다. 만약 아래의 실습에서 nltk.download('maxent_ne_chunker'), nltk.download('words') 등의 설치를 요구하는 에러 문구가 뜬다면, 지시하는대로 설치하면 됩니다."],"metadata":{"id":"Qqd0-otNgxLc"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","nltk.download('averaged_perceptron_tagger_eng')\n","nltk.download('maxent_ne_chunker_tab')\n","nltk.download('words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLsuRRbohlMu","executionInfo":{"status":"ok","timestamp":1750489465138,"user_tz":-540,"elapsed":1806,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"d790c64d-e011-42c1-adcb-d3e4eab28304"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from nltk import word_tokenize, pos_tag, ne_chunk\n","\n","sentence = \"James is working at Disney in London\"\n","# 토큰화 후 품사 태깅\n","tokenized_sentence = pos_tag(word_tokenize(sentence))\n","print(tokenized_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kn59v3mEghpB","executionInfo":{"status":"ok","timestamp":1750489465287,"user_tz":-540,"elapsed":145,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"00d66522-15d6-48c1-a911-920349992349"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"]}]},{"cell_type":"code","source":["# 개체명 인식\n","ner_sentence = ne_chunk(tokenized_sentence)\n","print(ner_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qO7UdHG-hY3s","executionInfo":{"status":"ok","timestamp":1750489465602,"user_tz":-540,"elapsed":313,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"651a1956-d041-41cb-fcf7-c730a67664f5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(S\n","  (PERSON James/NNP)\n","  is/VBZ\n","  working/VBG\n","  at/IN\n","  (ORGANIZATION Disney/NNP)\n","  in/IN\n","  (GPE London/NNP))\n"]}]},{"cell_type":"markdown","source":["ne_chunk는 개체명을 태깅하기 위해서 앞서 품사 태깅(pos_tag)이 수행되어야 합니다. 위의 결과에서 James는 PERSON(사람), Disney는 조직(ORGANIZATION), London은 위치(GPE)라고 정상적으로 개체명 인식이 수행된 것을 볼 수 있습니다. 이제 인공 신경망을 이용하여 개체명 인식 모델을 만들어보겠습니다."],"metadata":{"id":"VEdX1SeriF3f"}},{"cell_type":"markdown","source":["###3. 양방향 LSTM을 이용한 개체명 인식\n"],"metadata":{"id":"stcEwp_SiHUn"}},{"cell_type":"markdown","source":["###데이터 로드 및 단어 토큰화"],"metadata":{"id":"6bvPMgsSiQPd"}},{"cell_type":"code","source":["import urllib.request\n","import numpy as np\n","from tqdm import tqdm\n","import re\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"612YD6d2h1_V","executionInfo":{"status":"ok","timestamp":1750489465611,"user_tz":-540,"elapsed":6,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["NLTK를 이용하면 영어 코퍼스에 토큰화와 품사 태깅 전처리를 진행한 문장 데이터를 받아올 수 있습니다. 해당 데이터를 훈련시켜 품사 태깅을 수행하는 모델을 만들어보겠습니다. 저자의 깃허브로부터 데이터를 다운로드합니다."],"metadata":{"id":"QTjLIrB0iy_0"}},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"train.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAt7uCwsiwZv","executionInfo":{"status":"ok","timestamp":1750489466538,"user_tz":-540,"elapsed":921,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"47ac8f5a-ebd6-4159-8654-1394989fa4dd"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('train.txt', <http.client.HTTPMessage at 0x7e9cf7ee9190>)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["f = open('train.txt', 'r')\n","tagged_sentences = []\n","sentence = []\n","\n","for line in f:\n","    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n","        if len(sentence) > 0:\n","            tagged_sentences.append(sentence)\n","            sentence = []\n","        continue\n","    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n","    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n","    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n","    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다.\n","\n","print(\"전체 샘플 개수: \", len(tagged_sentences)) # 전체 샘플의 개수 출력\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UUdMLGfpkXcM","executionInfo":{"status":"ok","timestamp":1750489467102,"user_tz":-540,"elapsed":56,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"f07e2648-6289-4fe6-a5cc-fb5ff1332ba0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플 개수:  14041\n"]}]},{"cell_type":"code","source":["# 첫번째 샘플만 출력\n","print(tagged_sentences[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rG9uDCWGkvUA","executionInfo":{"status":"ok","timestamp":1750489467119,"user_tz":-540,"elapsed":12,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"1703c4b5-96ac-4ef3-f317-f79bf4feecc1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"]}]},{"cell_type":"markdown","source":["각 문장 샘플에 대해서 단어는 sentences에 태깅 정보는 pos_tags에 저장하고 첫번째 문장 샘플을 출력해보겠습니다."],"metadata":{"id":"BIALGPV4nVLL"}},{"cell_type":"code","source":["sentences, ner_tags = [], []\n","for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 가져온다\n","  sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n","  sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n","  ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장\n","\n","print(sentences[0])\n","print(ner_tags[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMxdpjy_m7Jr","executionInfo":{"status":"ok","timestamp":1750489467321,"user_tz":-540,"elapsed":35,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"738bbf21-3f86-4f77-d741-7cd6cfb15d09"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n","['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["첫번째 샘플에 대해서 단어에 대해서 sentences[0]에, 품사에 대해서만 pos_tags[0]에 저장된 것을 볼 수 있습니다. 뒤에서 보겠지만, sentences는 예측을 위한 X에 해당되며 pos_tags는 예측 대상인 y에 해당됩니다. 임의로 12번 인덱스 샘플에 대해서도 확인해보겠습니다"],"metadata":{"id":"qTYbEQQEoUGt"}},{"cell_type":"code","source":["print(sentences[12])\n","print(ner_tags[12])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJzQmh1yoKxa","executionInfo":{"status":"ok","timestamp":1750489467339,"user_tz":-540,"elapsed":14,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"f2188565-88bc-4d03-b8eb-f45fcd856303"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['only', 'france', 'and', 'britain', 'backed', 'fischler', \"'s\", 'proposal', '.']\n","['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-PER', 'O', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["단어에 대해서만 sentences[12]에, 또한 품사에 대해서만 pos_tags[12]에 저장된 것을 확인할 수 있습니다. 또한 첫번째 샘플과 길이가 다른 것을 볼 수 있습니다. 이제 훈련 데이터와 테스트 데이터를 분리해봅시다."],"metadata":{"id":"69FL74N5ojS6"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(sentences, ner_tags, test_size =0.2, random_state=777)\n"],"metadata":{"id":"K2ltvsEhodCW","executionInfo":{"status":"ok","timestamp":1750489467385,"user_tz":-540,"elapsed":27,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["학습이 진행되는 동안 성능을 확인하기 위한 검증 데이터 또한 분리합니다."],"metadata":{"id":"iytUi7Wxozar"}},{"cell_type":"code","source":["X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=777)"],"metadata":{"id":"_IVK4pbwowuj","executionInfo":{"status":"ok","timestamp":1750489467394,"user_tz":-540,"elapsed":3,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["학습 데이터, 검증 데이터, 테스트 데이터의 개수는 다음과 같습니다."],"metadata":{"id":"vDXNkgi_pEmw"}},{"cell_type":"code","source":["print('훈련 데이터의 개수 :', len(X_train))\n","print('검증 데이터의 개수 :', len(X_valid))\n","print('테스트 데이터의 개수 :', len(X_test))\n","print('훈련 데이터 레이블의 개수 :', len(X_train))\n","print('검증 데이터 레이블의 개수 :', len(X_valid))\n","print('테스트 데이터 레이블의 개수 :', len(X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggDUtruVpBKf","executionInfo":{"status":"ok","timestamp":1750489467431,"user_tz":-540,"elapsed":34,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"9b9c3411-d839-4256-803f-db069d4235bb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터의 개수 : 8985\n","검증 데이터의 개수 : 2247\n","테스트 데이터의 개수 : 2809\n","훈련 데이터 레이블의 개수 : 8985\n","검증 데이터 레이블의 개수 : 2247\n","테스트 데이터 레이블의 개수 : 2809\n"]}]},{"cell_type":"markdown","source":["학습 데이터의 상위 2개 샘플만 출력해봅시다. 현재 데이터는 단어 토큰화가 된 상태입니다."],"metadata":{"id":"HaIK3TYipPjc"}},{"cell_type":"code","source":["for sent in X_train[:2]:\n","  print(sent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRuDNeuvpLZ-","executionInfo":{"status":"ok","timestamp":1750489467443,"user_tz":-540,"elapsed":10,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"f218098a-9c13-404a-cfbe-ebb41a72eb09"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n","['hentgen', '(', '17-7', ')', 'surrendered', 'just', 'three', 'doubles', 'and', 'a', 'pair', 'of', 'singles', 'in', 'tossing', 'his', 'major-league', 'leading', 'ninth', 'complete', 'game', '.']\n"]}]},{"cell_type":"markdown","source":["### Vocab 만들기\n","단어 집합을 만들어봅시다. 각 단어의 등장 빈도를 카운트해주는 Counter를 사용하여 각 단어별 빈도수를 기록합니다. 이렇게 기록된 단어의 총 종류를 출력하여 총 단어수를 확인해봅시다."],"metadata":{"id":"HyuKKKZQuXtj"}},{"cell_type":"code","source":["word_list = []\n","for sent in X_train:\n","  for word in sent:\n","    word_list.append(word)\n","\n","word_counts = Counter(word_list)\n","print('총 단어수: ',len(word_counts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bi5CsejCpUu1","executionInfo":{"status":"ok","timestamp":1750489467507,"user_tz":-540,"elapsed":61,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"888f408d-b4d7-4ce8-fe12-89708225ba55"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["총 단어수:  16742\n"]}]},{"cell_type":"markdown","source":["단어수는 16,742개입니다. 임의로 영단어 the와 love의 등장횟수를 확인해보겠습니다."],"metadata":{"id":"oO1ig3-Vuzxc"}},{"cell_type":"code","source":["print('훈련 데이터에서의 단어 the의 등장횟수: ', word_counts['the'])\n","print('훈련 데이터에서의 단어 love의 등장횟수: ', word_counts['love'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZBWK6rMuu8E","executionInfo":{"status":"ok","timestamp":1750489467527,"user_tz":-540,"elapsed":17,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"1c22312e-0126-423d-9f1c-958e0a9d3062"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터에서의 단어 the의 등장횟수:  5410\n","훈련 데이터에서의 단어 love의 등장횟수:  7\n"]}]},{"cell_type":"markdown","source":["영단어 the의 등장 횟수는 5,410회이며, 영단어 love의 등장 횟수는 7회입니다. word_counts를 정렬하고 등장 빈도 상위 10개 단어를 출력해봅시다."],"metadata":{"id":"MkVp1e8lvHC1"}},{"cell_type":"code","source":["vocab = sorted(word_counts, key = word_counts.get , reverse = True)\n","print('등장 빈도수 상위 10개 단어')\n","print(vocab[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Thdifp_vD6B","executionInfo":{"status":"ok","timestamp":1750489467548,"user_tz":-540,"elapsed":11,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"fafe66b4-c5b5-43d2-f589-7bb755edb8c9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["등장 빈도수 상위 10개 단어\n","['the', ',', '.', 'of', 'in', 'to', 'a', ')', '(', 'and']\n"]}]},{"cell_type":"markdown","source":["이제 단어 집합을 만들기 위해서 패딩을 위한 토큰, 그리고 OOV 문제(Out-Of-Vocabulary) 발생 시에 사용하는 UNK 토큰을 위한 정수 0과 1을 각각 단어 집합에 할당합니다."],"metadata":{"id":"DpXCL1qUvjFJ"}},{"cell_type":"code","source":["word_to_index = {}\n","word_to_index['<PAD>'] = 0\n","word_to_index['<UNK>'] = 1\n","\n","for index, word in enumerate(vocab) :\n","  word_to_index[word] = index + 2\n","\n","vocab_size = len(word_to_index)\n","print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RW4aWDe7vewI","executionInfo":{"status":"ok","timestamp":1750489467560,"user_tz":-540,"elapsed":9,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"9d69d70a-1bc9-4c49-add9-4115ab142db1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 16744\n"]}]},{"cell_type":"markdown","source":["### 정수 인코딩\n","텍스트를 정수로 변환해주는 함수를 만듭니다. 해당 함수는 OOV 문제가 발생할 경우 해당 단어는 토큰과 맵핑되는 정수인 1로 변환합니다."],"metadata":{"id":"rJhDrF9qwSMF"}},{"cell_type":"code","source":["def texts_to_sequences(tokenized_X_data, word_to_index):\n","  encoded_X_data = []\n","  for sent in tokenized_X_data:\n","    index_sequences = []\n","    for word in sent:\n","      try:\n","        index_sequences.append(word_to_index[word])\n","      except KeyError:\n","        index_sequences.append(word_to_index['<UNK>'])\n","    encoded_X_data.append(index_sequences)\n","  return encoded_X_data"],"metadata":{"id":"In1auIcAwDX1","executionInfo":{"status":"ok","timestamp":1750489467617,"user_tz":-540,"elapsed":4,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 정수 인코딩을 진행합니다."],"metadata":{"id":"URKb2r1Cw7V7"}},{"cell_type":"code","source":["encoded_X_train = texts_to_sequences(X_train, word_to_index)\n","encoded_X_valid = texts_to_sequences(X_valid, word_to_index)\n","encoded_X_test = texts_to_sequences(X_test, word_to_index)"],"metadata":{"id":"hOyeK4N2w433","executionInfo":{"status":"ok","timestamp":1750489467627,"user_tz":-540,"elapsed":5,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["정수 인코딩 된 상위 샘플 2개만 출력해봅시다."],"metadata":{"id":"HHvevOFxxRae"}},{"cell_type":"code","source":["# 상위 샘플 2개 출력\n","for sent in encoded_X_train[:2]:\n","  print(sent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yL6t29eZxBTV","executionInfo":{"status":"ok","timestamp":1750489467648,"user_tz":-540,"elapsed":18,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"856285c7-ca97-4d36-e397-fb19b5cdd914"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[1260, 3215, 117, 17, 21, 123, 56, 539, 23]\n","[5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]\n"]}]},{"cell_type":"markdown","source":["정수로부터 단어로 변환하는 word_to_index의 key와 value를 반대로 저장하여 index_to_word를 만들고, 정수 인코딩 된 첫번째 샘플을 복원해봅시다."],"metadata":{"id":"PAIODGLhxWMZ"}},{"cell_type":"code","source":["index_to_word = {}\n","for key, value in word_to_index.items():\n","  index_to_word[value] = key\n","\n","decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n","print('기존의 첫번째 샘플: ', X_train[0])\n","print('복원된 첫번째 샘플: ', decoded_sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3d9_FdUxS-Y","executionInfo":{"status":"ok","timestamp":1750489467663,"user_tz":-540,"elapsed":12,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"f83154d4-b242-4041-8716-8f6a81728895"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["기존의 첫번째 샘플:  ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n","복원된 첫번째 샘플:  ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n"]}]},{"cell_type":"markdown","source":["이제 레이블에 대해서도 정수 인코딩을 진행해야 합니다. 레이블에 존재하는 모든 단어들의 집합을 구해봅시다."],"metadata":{"id":"lcdjyVW8x4lD"}},{"cell_type":"code","source":["# y_train으로부터 존재하는 모든 태그들의 집합 구하기\n","\n","flatten_tags = [tag for sent in y_train for tag in sent]\n","# 이 코드는 각 문장(sent) 안의 각 태그(tag)를 꺼내서 하나의 리스트로 합치는 것.\n","\n","tag_vocab = list(set(flatten_tags))\n","print('태그 집합: ', tag_vocab)\n","print('태그의 집합의 크기: ', len(tag_vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtInQ3uFx1Fv","executionInfo":{"status":"ok","timestamp":1750489467678,"user_tz":-540,"elapsed":13,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"5c728ef2-37b9-42ab-c8de-97589c495dfc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["태그 집합:  ['I-PER', 'I-MISC', 'B-MISC', 'I-ORG', 'B-ORG', 'I-LOC', 'B-LOC', 'B-PER', 'O']\n","태그의 집합의 크기:  9\n"]}]},{"cell_type":"markdown","source":["레이블의 각 단어에 정수를 부여하여 단어 집합(Vocabulary)를 만듭니다."],"metadata":{"id":"oARgub21zlhk"}},{"cell_type":"code","source":["tag_to_index = {}\n","tag_to_index['<PAD>'] = 0\n","\n","for index, word in enumerate(tag_vocab):\n","  tag_to_index[word] = index+1\n","\n","tag_vocab_size = len(tag_to_index)\n","print('태그 집합: ', tag_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_kEcLcwzAJ3","executionInfo":{"status":"ok","timestamp":1750489467698,"user_tz":-540,"elapsed":18,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"bd6fe5df-a4f8-4d48-cb83-be401799316d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["태그 집합:  {'<PAD>': 0, 'I-PER': 1, 'I-MISC': 2, 'B-MISC': 3, 'I-ORG': 4, 'B-ORG': 5, 'I-LOC': 6, 'B-LOC': 7, 'B-PER': 8, 'O': 9}\n"]}]},{"cell_type":"markdown","source":["many-to-many 문제의 경우에는 레이블도 시퀀스 데이터가 되므로 각 레이블을 정수 시퀀스로 변환해줍니다. 다시 말해 레이블에 대해서 정수 인코딩을 진행합니다. 이를 위해 tag_to_index를 이용하여 레이블의 각 단어를 정수로 변환하는 함수인 encoding_label() 함수를 구현합니다."],"metadata":{"id":"dSNi_sc23TSE"}},{"cell_type":"code","source":["def encoding_label(sequence, tag_to_index):\n","  label_sequence = []\n","  for seq in sequence:\n","    label_sequence.apeend([tag_to_index[tag] for tag in seq])\n","  return label_sequence"],"metadata":{"id":"2a8JY6Zx0Pm6","executionInfo":{"status":"ok","timestamp":1750489467703,"user_tz":-540,"elapsed":3,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["학습 데이터, 검증 데이터, 테스트 데이터의 레이블에 대해서 정수 인코딩을 진행합니다."],"metadata":{"id":"ZCmrj2Sx3pLs"}},{"cell_type":"code","source":["encoded_y_train = texts_to_sequences(y_train, tag_to_index)\n","encoded_y_valid = texts_to_sequences(y_valid, tag_to_index)\n","encoded_y_test = texts_to_sequences(y_test, tag_to_index)"],"metadata":{"id":"MzXKr3sS3maP","executionInfo":{"status":"ok","timestamp":1750489467761,"user_tz":-540,"elapsed":6,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print('X 데이터 상위 2개')\n","print(encoded_X_train[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iY0ZKhHq4RUC","executionInfo":{"status":"ok","timestamp":1750489467778,"user_tz":-540,"elapsed":13,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"0a239963-df5f-47d7-f84a-b1cb1b6259e9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["X 데이터 상위 2개\n","[[1260, 3215, 117, 17, 21, 123, 56, 539, 23], [5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]]\n"]}]},{"cell_type":"markdown","source":["### 패딩\n","데이터의 길이를 동일하게 맞춰주는 작업인 패딩을 위해서는 각 데이터의 길이 분포를 확인할 필요가 있습니다"],"metadata":{"id":"xk9xgdFq4eJD"}},{"cell_type":"code","source":["print(\"샘플의 최대길이 : %d\" % max(len(l) for l in encoded_X_train))\n","print('샘플의 평균 길이 : %f' % (sum(map(len, encoded_X_train))/len(encoded_X_train)))\n","\n","plt.hist([len(s) for s in encoded_X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"id":"GNRMrx7v4ask","executionInfo":{"status":"ok","timestamp":1750489467861,"user_tz":-540,"elapsed":80,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"7e6d5c0d-5ab5-4e07-fbc4-e62aa6bf6cf6"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["샘플의 최대길이 : 78\n","샘플의 평균 길이 : 14.518420\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["가장 긴 샘플의 길이는 78이며, 그래프를 봤을 때 전체 데이터의 길이 분포는 대체적으로 약 50내외의 길이를 가지는 것을 볼 수 있습니다. 모델이 처리할 수 있도록 encoded_X_train과 encoded_X_test의 모든 샘플의 길이를 특정 길이로 동일하게 맞춰줄 필요가 있습니다. 특정 길이 변수를 max_len으로 정합니다. 대부분의 리뷰가 내용이 잘리지 않도록 할 수 있는 최적의 max_len의 값은 몇일까요? 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수를 만듭니다."],"metadata":{"id":"EZ_27DzS5eea"}},{"cell_type":"code","source":["def below_threshold_len(max_len, nested_list):\n","  count = 0\n","  for sentence in nested_list:\n","    if(len(sentence)<= max_len):\n","      count = count +1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s' %(max_len, (count/len(nested_list))*100))"],"metadata":{"id":"9CHD39U85MI6","executionInfo":{"status":"ok","timestamp":1750489467874,"user_tz":-540,"elapsed":9,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["사실 최대 길이가 78이므로 78로 패딩해도 됩니다. 여기서는 80정도로 패딩해보겠습니다."],"metadata":{"id":"MZbIEnnA6gd7"}},{"cell_type":"code","source":["max_len = 80\n","below_threshold_len(max_len, encoded_X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPkn5Ljl6bBL","executionInfo":{"status":"ok","timestamp":1750489467896,"user_tz":-540,"elapsed":17,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"a93310ec-4cbd-4c5d-a2be-488dc52a43fe"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플 중 길이가 80 이하인 샘플의 비율: 100.0\n"]}]},{"cell_type":"markdown","source":["모든 데이터의 길이를 80으로 패딩해보겠습니다. max_len을 인자로 입력받아서 max_len보다 짧은 데이터의 경우에는 뒤에 0을 추가하는 함수인 pad_sequences()를 구현합니"],"metadata":{"id":"t651VlUQ6r4b"}},{"cell_type":"code","source":["def pad_sequences(sentences, max_len):\n","    features = np.zeros((len(sentences), max_len), dtype=int)\n","    for index, sentence in enumerate(sentences):\n","        if len(sentence) != 0:\n","            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","    return features"],"metadata":{"id":"V0G3pocO6oV6","executionInfo":{"status":"ok","timestamp":1750489467943,"user_tz":-540,"elapsed":43,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["함수 pad_sequences()로 훈련 데이터, 검증 데이터, 테스트 데이터를 패딩합니다. 이때 개체명 인식과 같은 Many-to-Many 문제를 푸는 경우에는 레이블도 패딩해주어야 합니다. 패딩 후에 모든 데이터 길이가 80으로 패딩되었는지 확인합니다."],"metadata":{"id":"f_1UC9M87d0Y"}},{"cell_type":"code","source":["padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n","padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n","padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n","\n","padded_y_train = pad_sequences(encoded_y_train, max_len=max_len)\n","padded_y_valid = pad_sequences(encoded_y_valid, max_len=max_len)\n","padded_y_test = pad_sequences(encoded_y_test, max_len=max_len)\n","\n","print('훈련 데이터의 크기 :', padded_X_train.shape)\n","print('검증 데이터의 크기 :', padded_X_valid.shape)\n","print('테스트 데이터의 크기 :', padded_X_test.shape)\n","print('-' * 30)\n","print('훈련 데이터의 레이블 :', padded_y_train.shape)\n","print('검증 데이터의 레이블 :', padded_y_valid.shape)\n","print('테스트 데이터의 레이블 :', padded_y_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZ08wd5C7bSL","executionInfo":{"status":"ok","timestamp":1750489468027,"user_tz":-540,"elapsed":78,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"f317b94a-3b7a-4c05-944b-8950d43ca72a"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터의 크기 : (8985, 80)\n","검증 데이터의 크기 : (2247, 80)\n","테스트 데이터의 크기 : (2809, 80)\n","------------------------------\n","훈련 데이터의 레이블 : (8985, 80)\n","검증 데이터의 레이블 : (2247, 80)\n","테스트 데이터의 레이블 : (2809, 80)\n"]}]},{"cell_type":"code","source":["# 패딩 후의 데이터를 확인해보겠습니다.\n","print(padded_X_train[:2])\n","print('-' * 5 + '레이블' + '-' * 5)\n","print(padded_y_train[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmUbe9Z-7f9Q","executionInfo":{"status":"ok","timestamp":1750489468043,"user_tz":-540,"elapsed":19,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"c53e1a06-c785-4a3b-cfa2-e9e207a46876"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1260 3215  117   17   21  123   56  539   23    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0]\n"," [5456   10 8229    9 8230  186   84 1815   11    8 1073    5  421    6\n","  8231   35 2043  291  790  957  267    4    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0    0    0    0    0    0    0]]\n","-----레이블-----\n","[[5 4 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0]\n"," [8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","  0 0 0 0 0 0 0 0]]\n"]}]},{"cell_type":"markdown","source":["### 모델링\n","이제 모델을 구현해봅시다."],"metadata":{"id":"LiJ5f35y8Hth"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"metadata":{"id":"5OyK7rMu7xhM","executionInfo":{"status":"ok","timestamp":1750489472085,"user_tz":-540,"elapsed":4038,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# GPU를 사용 가능한 환경인지 확인합니다.\n","USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"cpu와 cuda 중 다음 기기로 학습함\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgE4Dz9g8U19","executionInfo":{"status":"ok","timestamp":1750489472573,"user_tz":-540,"elapsed":285,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"b0cd5e17-13d9-45ca-8788-783236f13602"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu와 cuda 중 다음 기기로 학습함 cuda\n"]}]},{"cell_type":"markdown","source":["\n","\n","이제 개체명 인식 모델을 만들어봅시다. 만약, 단방향 GRU를 모델로 사용할 경우 코드는 아래와 같습니다."],"metadata":{"id":"C0TxoFRV8yv7"}},{"cell_type":"code","source":["class NERTagger(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n","    super(NERTagger,self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","    self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","  def forward(self, x):\n","    # x: (batch_size, seq_length)\n","    embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n","    gru_out, _ = self.gru(embedded)  # (batch_size, seq_length, hidden_dim)\n","    logits = self.fc(gru_out)  # (batch_size, seq_length, output_dim)\n","    return logits\n"],"metadata":{"id":"gDquWbNS8sy1","executionInfo":{"status":"ok","timestamp":1750489472581,"user_tz":-540,"elapsed":4,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["하지만 위의 GRU를 양방향 LSTM(Bidirectional LSTM) 2층짜리로 변경하려면 다음과 같이 수정하면 됩니다."],"metadata":{"id":"zf4mNjI39zph"}},{"cell_type":"code","source":["class NERTagger(nn.Module):\n","  def __init__(self,vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=2):\n","    super(NERTagger, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = num_layers, batch_first=True, bidirectional=True)\n","    self.fc = nn.Linear(hidden_dim*2, output_dim)\n","\n","  def forward(self, x):\n","    # x: (batch_size, seq_length)\n","    embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n","    lstm_out, _ = self.lstm(embedded)  # (batch_size, seq_length, hidden_dim*2)\n","    logits = self.fc(lstm_out)  # (batch_size, seq_length, output_dim)\n","    return logits"],"metadata":{"id":"2skhgcKW9vdG","executionInfo":{"status":"ok","timestamp":1750489472593,"user_tz":-540,"elapsed":6,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["위에서 작성한 GRU 코드와 양방향 LSTM 코드의 차이점을 봅시다.\n","\n","- nn.GRU를 nn.LSTM으로 변경했습니다.\n","- num_layers 매개변수를 추가하고 이를 nn.LSTM 생성자에 전달했습니다. 기본값은 2입니다.\n","- bidirectional=True를 추가하여 양방향 LSTM을 사용하도록 설정했습니다.\n","- nn.Linear의 입력 차원을 hidden_dim*2로 변경하여 양방향 LSTM의 출력을 처리하도록 했습니다.\n","\n"],"metadata":{"id":"FGAabsym-7E4"}},{"cell_type":"code","source":["# 사용할 데이터를 파이토치의 텐서로 변환하고, 배치 단위 처리를 위해 데이터로더로 변환합니다.\n","X_train_tensor = torch.tensor(padded_X_train, dtype=torch.long)\n","y_train_tensor = torch.tensor(padded_y_train, dtype=torch.long)\n","X_valid_tensor = torch.tensor(padded_X_valid, dtype=torch.long)\n","y_valid_tensor = torch.tensor(padded_y_valid, dtype=torch.long)\n","X_test_tensor = torch.tensor(padded_X_test, dtype=torch.long)\n","y_test_tensor = torch.tensor(padded_y_test, dtype=torch.long)\n","\n","train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n","\n","valid_dataset = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n","valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=False, batch_size=32)\n","\n","test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=32)\n"],"metadata":{"id":"BI2XwWTU-4q-","executionInfo":{"status":"ok","timestamp":1750489472602,"user_tz":-540,"elapsed":5,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["이제 위에서 선언한 NERTagger 클래스로부터 모델 객체를 만들어봅시다. 현재 단어 집합의 크기는 다음과 같습니다."],"metadata":{"id":"grivHggqEogh"}},{"cell_type":"code","source":["print('단어 집합의 크기:', vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhIaGvs8ENcb","executionInfo":{"status":"ok","timestamp":1750489472622,"user_tz":-540,"elapsed":16,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"adf5ab8a-9a90-406a-dbf3-49dcaafdbd5e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기: 16744\n"]}]},{"cell_type":"markdown","source":["모델 객체를 선언하기 위한 하이퍼파라미터 값은 다음과 같습니다. 임베딩 벡터의 차원은 100, LSTM의 은닉 상태의 차원은 256, 출력층의 차원은 tag_vocab_size이며 앞에서 확인한 바와 같이 10이며, 학습률(learning rate)는 0.01, 학습 횟수에 해당하는 에포크는 10, LSTM의 은닉층 수는 2로 지정했습니다."],"metadata":{"id":"5CnamsbqEzTu"}},{"cell_type":"code","source":["embedding_dim = 100\n","hidden_dim = 100\n","output_dim = tag_vocab_size\n","learning_rate = 0.01\n","num_epochs = 10\n","num_layers = 2"],"metadata":{"id":"YQkM5UgKEtYC","executionInfo":{"status":"ok","timestamp":1750489472627,"user_tz":-540,"elapsed":3,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# 모델 객체를 선언합니다.\n","model = NERTagger(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OGQgiKZGFBei","executionInfo":{"status":"ok","timestamp":1750489472653,"user_tz":-540,"elapsed":20,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"0fb94a0e-4dfe-4c77-9f68-a87cbbc795b4"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NERTagger(\n","  (embedding): Embedding(16744, 100)\n","  (lstm): LSTM(100, 100, num_layers=2, batch_first=True, bidirectional=True)\n","  (fc): Linear(in_features=200, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["앞으로 많이 사용하게 될 비용함수인 nn.CrossEntropyLoss에서는 ignore_index를 통해서 특정 인덱스에 대한 loss를 구하지 않을 수 있습니다. ignore_index=0을 사용하면 패딩 위치에 대해서는 loss를 구하지 않습니다."],"metadata":{"id":"Y7gbWJykFRw7"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters(), lr = learning_rate)"],"metadata":{"id":"7Ab8dtiZIFXd","executionInfo":{"status":"ok","timestamp":1750489476967,"user_tz":-540,"elapsed":4311,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["### 평가 코드 작성\n","학습하는 동안 학습 데이터와 검증 데이터에 대한 정확도와 loss를 구할 것이므로 학습하기 전에 평가 코드를 작성해야만 합니다. 우선 모델의 예측값과 실제값으로부터 정확도를 구하는 함수인 calculate_accuracy()를 작성합니다. 해당 함수에서 고려해야할 점은 패딩 토큰이 있는 부분에 대해서는 계산을 하지 않는다는 점입니다."],"metadata":{"id":"hjdImPEBFTv8"}},{"cell_type":"code","source":["def calculate_accuracy(logits, labels, ignore_index=0):\n","    # 예측 레이블을 구합니다.\n","    predicted = torch.argmax(logits, dim=1) # torch.argmax는 텐서 안에서 가장큰 값의 인덱스를 찾아주는 함수\n","\n","    # 패딩 토큰은 무시합니다.\n","    mask = (labels != ignore_index)\n","\n","    # 정답을 맞춘 경우를 집계합니다.\n","    correct = (predicted == labels).masked_select(mask).sum().item()\n","    total = mask.sum().item()\n","\n","    accuracy = correct / total\n","    return accuracy\n"],"metadata":{"id":"rvINqMnZLt-7","executionInfo":{"status":"ok","timestamp":1750489476981,"user_tz":-540,"elapsed":6,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["검증 데이터의 데이터로더로부터 모델의 성능을 측정하는 evaluate() 함수를 구현합니다. evaluate() 함수 내부에서는 위에서 작성한 calculate_accuracy()를 호출하여 사용하고 있습니다."],"metadata":{"id":"wdE3jPlJGHya"}},{"cell_type":"code","source":["def evaluate(model, valid_dataloader, criterion, device):\n","    val_loss = 0\n","    val_correct = 0\n","    val_total = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_X, batch_y in valid_dataloader:\n","            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","\n","            # Forward pass\n","            logits = model(batch_X)\n","\n","            # Compute loss\n","            loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n","\n","            # Calculate validation accuracy and loss\n","            val_loss += loss.item()\n","            val_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0) # .view()함수는 텐서 모양 재배열, .view(-1)은 1차원으로 평탄화\n","            val_total += batch_y.size(0)\n","\n","    val_accuracy = val_correct / val_total\n","    val_loss /= len(valid_dataloader)\n","\n","    return val_loss, val_accuracy\n"],"metadata":{"id":"-V3HaXNWQKDT","executionInfo":{"status":"ok","timestamp":1750489476986,"user_tz":-540,"elapsed":3,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["### 모델 학습하기"],"metadata":{"id":"P0xnBMM8IYKR"}},{"cell_type":"code","source":["# Training loop\n","best_val_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","    # Training\n","    train_loss = 0\n","    train_correct = 0\n","    train_total = 0\n","    model.train()\n","    for batch_X, batch_y in train_dataloader:\n","        # Forward pass\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        logits = model(batch_X)\n","\n","        # Compute loss\n","        loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Calculate training accuracy and loss\n","        train_loss += loss.item()\n","        train_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n","        train_total += batch_y.size(0)\n","\n","    train_accuracy = train_correct / train_total\n","    train_loss /= len(train_dataloader)\n","\n","    # Validation\n","    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}:')\n","    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n","    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # 검증 손실이 최소일 때 체크포인트 저장\n","    if val_loss < best_val_loss:\n","        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n"],"metadata":{"id":"HWLdHPfGLTUJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750489490230,"user_tz":-540,"elapsed":13240,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"ff146225-9755-4aac-aa55-8622f219c90e"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10:\n","Train Loss: 0.3581, Train Accuracy: 0.9036\n","Validation Loss: 0.2105, Validation Accuracy: 0.9392\n","Validation loss improved from inf to 0.2105. 체크포인트를 저장합니다.\n","Epoch 2/10:\n","Train Loss: 0.1076, Train Accuracy: 0.9685\n","Validation Loss: 0.1636, Validation Accuracy: 0.9525\n","Validation loss improved from 0.2105 to 0.1636. 체크포인트를 저장합니다.\n","Epoch 3/10:\n","Train Loss: 0.0428, Train Accuracy: 0.9873\n","Validation Loss: 0.1762, Validation Accuracy: 0.9505\n","Epoch 4/10:\n","Train Loss: 0.0215, Train Accuracy: 0.9936\n","Validation Loss: 0.2325, Validation Accuracy: 0.9390\n","Epoch 5/10:\n","Train Loss: 0.0150, Train Accuracy: 0.9955\n","Validation Loss: 0.2376, Validation Accuracy: 0.9435\n","Epoch 6/10:\n","Train Loss: 0.0120, Train Accuracy: 0.9963\n","Validation Loss: 0.2307, Validation Accuracy: 0.9504\n","Epoch 7/10:\n","Train Loss: 0.0103, Train Accuracy: 0.9968\n","Validation Loss: 0.2397, Validation Accuracy: 0.9495\n","Epoch 8/10:\n","Train Loss: 0.0168, Train Accuracy: 0.9946\n","Validation Loss: 0.2457, Validation Accuracy: 0.9457\n","Epoch 9/10:\n","Train Loss: 0.0258, Train Accuracy: 0.9918\n","Validation Loss: 0.2500, Validation Accuracy: 0.9462\n","Epoch 10/10:\n","Train Loss: 0.0185, Train Accuracy: 0.9939\n","Validation Loss: 0.2432, Validation Accuracy: 0.9481\n"]}]},{"cell_type":"markdown","source":["학습은 정해진 횟수(num_epochs)만큼 반복되는데, 여기서는 5번 반복하도록 설정되어 있습니다. 학습 과정에서는 train_dataloader에서 배치(batch) 단위로 데이터를 가져와서 모델에 입력합니다. 모델은 입력 데이터를 처리하여 예측값(logits)을 출력하고, 이를 실제 정답(batch_y)과 비교하여 손실(loss)을 계산합니다. 그 다음, 손실을 기반으로 모델의 가중치를 조정하는 역전파(backward pass)와 최적화(optimization) 과정을 거칩니다.\n","\n","각 배치마다 계산된 손실과 정확도는 에포크 단위로 누적되어 평균값으로 계산됩니다. 에포크가 끝날 때마다 학습 손실(train_loss), 학습 정확도(train_accuracy), 검증 손실(val_loss), 검증 정확도(val_accuracy)를 출력하여 모델의 성능을 모니터링합니다.\n","\n","검증 손실(val_loss)이 이전에 기록된 최소 검증 손실(best_val_loss)보다 작아지면, 해당 에포크의 모델 가중치를 체크포인트(checkpoint)로 저장합니다. 이를 통해 가장 성능이 좋은 모델을 저장할 수 있습니다. 이 과정을 설정된 에포크 수만큼 반복하면서 모델을 학습시키고, 최종적으로 가장 좋은 성능을 보인 모델의 가중치를 얻게 됩니다."],"metadata":{"id":"DFKDfkV5OVdz"}},{"cell_type":"markdown","source":["### 모델 로드 및 평가\n","위에서 저장해둔 Best 모델을 로드하여 정상 로드되었는지 확인하기 위해서 검증 데이터에 대한 정확도와 손실을 출력하고, 테스트 데이터에 대해서도 평가를 진행합니다."],"metadata":{"id":"28a77spNOids"}},{"cell_type":"code","source":["# 모델 로드\n","model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n","\n","# 모델을 device에 올립니다.\n","model.to(device)\n","\n","# 검증 데이터에 대한 정확도(accuracy)와 손실(loss) 계산\n","val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","print(f'Best model validation loss: {val_loss:.4f}')\n","print(f'Best model validation accuracy: {val_accuracy:.4f}')"],"metadata":{"id":"jwBcDC7_LWRW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750489490350,"user_tz":-540,"elapsed":94,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"49b78802-421e-49ce-bd54-e873a6914fee"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Best model validation loss: 0.1636\n","Best model validation accuracy: 0.9525\n"]}]},{"cell_type":"markdown","source":["테스트 데이터에 대해서도 정확도와 손실을 계산합니다.\n"],"metadata":{"id":"0c0fnjqyPSeR"}},{"cell_type":"code","source":["# 테스트 데이터에 대한 정확도와 손실 계산\n","test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n","\n","print(f'Best test loss: {test_loss:.4f}')\n","print(f'Best test accuracy: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vi_PB2dlPWy4","executionInfo":{"status":"ok","timestamp":1750489490523,"user_tz":-540,"elapsed":158,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"5fe0b41f-e05d-4e49-e7e4-a2648b167e1c"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Best test loss: 0.1601\n","Best test accuracy: 0.9530\n"]}]},{"cell_type":"markdown","source":["### 인퍼런스 및 테스트\n","모델을 서비스에 적용하게 되면 전처리가 전혀 되어있지 않은 임의의 텍스트 입력에 대해서 동작해야 할 것입니다. 임의의 텍스트 입력에 대해서 예측 레이블을 리턴하는 함수를 만들어봅시다."],"metadata":{"id":"VSnJ-69dQduH"}},{"cell_type":"code","source":["index_to_tag = {}\n","for key, value in tag_to_index.items():\n","  index_to_tag[value] = key\n","\n","def predict_labels(text, model, word_to_ix, index_to_tag, max_len=150):\n","  # 단어 토큰화\n","  tokens = text.split()\n","\n","  # 정수 인코딩\n","  token_indices = [word_to_ix.get(token, 1) for token in tokens]\n","\n","  # 패딩\n","  token_indices_padded = np.zeros(max_len, dtype=int)\n","  token_indices_padded[:len(token_indices)] = token_indices[:max_len]\n","\n","  # 텐서로 변환\n","  input_tensor = torch.tensor(token_indices_padded, dtype=torch.long).unsqueeze(0).to(device)\n","\n","  # 모델의 입력으로 사용하고 예측값 리턴\n","  model.eval()\n","  with torch.no_grad():\n","    logits = model(input_tensor)\n","\n","  # 가장 값이 높은 인덱스를 예측값으로 선택\n","  predicted_indices = torch.argmax(logits, dim=-1).squeeze(0).tolist()\n","\n","  # 패딩 토큰 제거\n","  predicted_indices_no_pad = predicted_indices[:len(tokens)]\n","\n","  # 패딩 토큰을 제외하고 정수 시퀀스를 예측 시퀀스로 변환\n","  predicted_tags = [index_to_tag[index] for index in predicted_indices_no_pad]\n","\n","  return predicted_tags"],"metadata":{"id":"WjuC0qc5PoNs","executionInfo":{"status":"ok","timestamp":1750489490554,"user_tz":-540,"elapsed":17,"user":{"displayName":"유진철","userId":"18428759730043573350"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["학습에 사용되지 않은 테스트 데이터의 첫번째 샘플을 이용해봅시다. 현재 이 데이터는 이미 단어 토큰화가 된 상태라서 단어 토큰화 이전 상태로 되돌려 전처리가 전혀 되어있지 않은 입력을 가정하고 함수에 입력으로 사용하겠습니다."],"metadata":{"id":"m2bcsNomSwem"}},{"cell_type":"code","source":["print(X_test[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scUJJPkISw_X","executionInfo":{"status":"ok","timestamp":1750489490573,"user_tz":-540,"elapsed":13,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"3ea9c421-6826-4b41-ef19-49a22cf5f7f5"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["['feyenoord', 'rotterdam', 'suffered', 'an', 'early', 'shock', 'when', 'they', 'went', '1-0', 'down', 'after', 'four', 'minutes', 'against', 'de', 'graafschap', 'doetinchem', '.']\n"]}]},{"cell_type":"markdown","source":["토큰화 이전 상태로 돌린 후는 다음과 같습니다."],"metadata":{"id":"G1x4CPsOS0jt"}},{"cell_type":"code","source":["sample = ' '.join(X_test[0])\n","print(sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cna0hc0QSzSt","executionInfo":{"status":"ok","timestamp":1750489490609,"user_tz":-540,"elapsed":32,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"544d7796-4431-43a2-9a29-f6dc16f432f5"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["feyenoord rotterdam suffered an early shock when they went 1-0 down after four minutes against de graafschap doetinchem .\n"]}]},{"cell_type":"markdown","source":["실제 레이블과 예측값을 비교해봅시다."],"metadata":{"id":"3TiV6jvvTAbU"}},{"cell_type":"code","source":["predicted_tags = predict_labels(sample, model, word_to_index, index_to_tag)\n","print('예측 : ', predicted_tags)\n","print('실제값 : ', y_test[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1DcNbY7SS_o6","executionInfo":{"status":"ok","timestamp":1750489490629,"user_tz":-540,"elapsed":16,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"582e96ea-c60c-436e-eb6e-3b0a00b4ee27"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["예측 :  ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-LOC', 'I-LOC', 'O']\n","실제값 :  ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']\n"]}]}]}