{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNDeBfE0GRCuhd10zJOfiP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. 원핫 인코딩(one-hot encoding)\n"],"metadata":{"id":"Pc4AuP6zSM11"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNv5NPn_SJdp","executionInfo":{"status":"ok","timestamp":1748677652914,"user_tz":-540,"elapsed":20,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"0d4424c5-f82d-464e-e3da-296d24ee000d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n"]}],"source":["## no library\n","def one_hot(word_list):\n","  # 1. 단어의 중복을 제거해 준다\n","  word_list = list(set(word_list))\n","  # 2. 단어의 수만큼 배열을 만들고, 0으로 채워줍니다.\n","  encoding_matrix = [[0 for col in range(len(word_list))] for row in range(len(word_list))]\n","  # 3. 해당 단어의 인덱스를 찾고, 그 부분을 1로 만들어줍니다.\n","  for index, word in enumerate(word_list):\n","    encoding_matrix[index][index] = 1\n","  return encoding_matrix\n","\n","labels = ['cat', 'dog', 'rabbit', 'tutle']\n","\n","print(one_hot(labels))"]},{"cell_type":"code","source":["## pandas를 사용한 원핫 인코딩\n","import pandas as pd\n","\n","label_dict = {'label':['cat','dog','rabbit','turtle']}\n","#df = pd.DataFrame(label_dict)\n","one_hot_encoding = pd.get_dummies(label_dict['label'])\n","print(one_hot_encoding)\n","\n","## sklearn를 사용한 원핫 인코딩\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","\n","label_dict = {'label':['cat','dog','rabbit','turtle']}\n","df = pd.DataFrame(label_dict)\n","one_hot = OneHotEncoder()\n","one_hot_encoding = one_hot.fit_transform(df)\n","print(one_hot_encoding)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IioUe5JOTb7L","executionInfo":{"status":"ok","timestamp":1748677792209,"user_tz":-540,"elapsed":35,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"5da978db-4238-46d8-b4bd-6ff3210185bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     cat    dog  rabbit  turtle\n","0   True  False   False   False\n","1  False   True   False   False\n","2  False  False    True   False\n","3  False  False   False    True\n","<Compressed Sparse Row sparse matrix of dtype 'float64'\n","\twith 4 stored elements and shape (4, 4)>\n","  Coords\tValues\n","  (0, 0)\t1.0\n","  (1, 1)\t1.0\n","  (2, 2)\t1.0\n","  (3, 3)\t1.0\n"]}]},{"cell_type":"markdown","source":["#2. BoW(Bag of Word)\n","\n"],"metadata":{"id":"D0oeberkUbr-"}},{"cell_type":"code","source":["## no library\n","def bow(sentence):\n","  #(1) 입력받은 문장을 단어 단위로 쪼갠 뒤, 중복을 제거해줍니다.\n","  word_list = sentence.split(' ')\n","  word_list = list(set(word_list))\n","  #(2) 단어의 수만큼 배열을 만들고, 0으로 채워줍니다.\n","  embedding_matrix = [0 for element in range(len(word_list))]\n","  #(3) 각 인덱스의 단어가 몇 번 나오는지 count한뒤, 갱신해줍니다.\n","  for index, word in enumerate(word_list):\n","    embedding_matrix[index] = sentence.count(word)\n","  return word_list, embedding_matrix\n","\n","sentence = \"jin is very very handsome guy and cheol is very handsome guy too\"\n","\n","word_list, bow_embedding = bow(sentence)\n","\n","print(\"word_list : \",word_list,\", embedding : \",bow_embedding)\n","\n","# and가 3번 나온 이유는 handsome에 and가 포함되어 있어서"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NbEY_kHjUksG","executionInfo":{"status":"ok","timestamp":1748678048849,"user_tz":-540,"elapsed":16,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"d896c465-e96a-4866-8696-e8b4903383b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["word_list :  ['and', 'is', 'too', 'cheol', 'guy', 'jin', 'very', 'handsome'] , embedding :  [3, 2, 1, 1, 2, 1, 3, 2]\n"]}]},{"cell_type":"code","source":["## using sklearn\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","sentence = [\"jin is very very handsome man and cheol is very handsome man too\"]\n","vectorizer = CountVectorizer(min_df = 1, ngram_range = (1,1))\n","embedding = vectorizer.fit_transform(sentence)\n","vocab = vectorizer.get_feature_names_out()\n","print(\"word_list : \",vocab,\", embedding : \",embedding.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1k9mkZiVXsm","executionInfo":{"status":"ok","timestamp":1748678650570,"user_tz":-540,"elapsed":18,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"d6812611-b6b0-4023-c1ff-ca089a9e7080"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["word_list :  ['and' 'cheol' 'handsome' 'is' 'jin' 'man' 'too' 'very'] , embedding :  [[1 1 2 2 1 2 1 3]]\n"]}]},{"cell_type":"markdown","source":["# 3. Word2Vec(CBOW, Skip_Gram 두 개 구현)\n","\n","# CBOW\n","#### CBOW의 경우, 한 단어가 제거되고 주변 단어들로부터 해당 단어가 예측됩니다.따라서 여러 개의 입력 벡터를 모델에 입력으로 사용하여 하나의 출력 벡터를 생성합니다."],"metadata":{"id":"nDAN66UsYAyC"}},{"cell_type":"code","source":["## using pytorch\n","import torch\n","import torch.nn as nn\n","\n","EMBEDDING_DIM = 128\n","EPOCHS = 100\n","\n","example_sentence = \"\"\"In the case of CBOW, one word is eliminated, and the word is predicted from surrounding words.\n","Therefore, it takes multiple input vectors as inputs to the model and creates one output vector.\n","In contrast, Skip-Gram learns by removing all words except one word and predicting the surrounding words in the context through one word.\n","So, it takes a vector as input and produces multiple output vectors.\n","CBOW and Skip-Gram are different.\"\"\".split()\n","\n","#1 입력받은 문장을 단어로 쪼개고, 중복을 제거해줍니다.\n","vocab = set(example_sentence)\n","vocab_size = len(example_sentence)\n","\n","#(2) 단어 : 인덱스, 인덱스 : 단어를 가지는 딕셔너리를 선언해 줍니다.\n","word_to_index = {word:index for index, word in enumerate(vocab)}\n","index_to_word = {index:word for index, word in enumerate(vocab)}\n","\n","# #3 학습을 위한 데이터를 생성해 줍니다.\n","data = make_data(example_sentence)\n","\n","# convert context to index vector\n","def make_context_vector(context, word_to_ix):\n","  idxs = [word_to_ix[w] for w in context]\n","  return torch.tensor(idxs, dtype=torch.long)\n","\n","# make dataset function\n","def make_data(sentence):\n","  data = []\n","  for i in range(2, len(example_sentence) - 2):\n","    context = [example_sentence[i - 2], example_sentence[i - 1], example_sentence[i + 1], example_sentence[i + 2]]\n","    target = example_sentence[i]\n","    data.append((context, target))\n","  return data\n","\n","#4 CBOW 모델을 정의해 줍니다.\n","class CBOW(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim):\n","    super(CBOW, self).__init__()\n","\n","    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","    self.layer1 = nn.Linear(embedding_dim, 64)\n","    self.activation1 = nn.ReLU()\n","\n","    self.layer2 = nn.Linear(64, vocab_size)\n","    self.activation2 = nn.LogSoftmax(dim = -1)\n","\n","  def forward(self, inputs):\n","    embeded_vector = sum(self.embeddings(inputs)).view(1,-1)\n","    output = self.activation1(self.layer1(embeded_vector))\n","    output = self.activation2(self.layer2(output))\n","    return output\n","\n","#5 모델을 선언해주고, loss function, optimizer등을 선언해줍니다.\n","model = CBOW(vocab_size, EMBEDDING_DIM)\n","loss_function = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","\n","#6 학습을 진행합니다.\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    for context, target in data:\n","        context_vector = make_context_vector(context, word_to_index)\n","        log_probs = model(context_vector)\n","        total_loss += loss_function(log_probs, torch.tensor([word_to_index[target]]))\n","    print('epoch = ',epoch, ', loss = ',total_loss)\n","    optimizer.zero_grad()\n","    total_loss.backward()\n","    optimizer.step()\n","\n","#7 test하고 싶은 문장을 뽑고, test를 진행합니다.\n","test_data = ['CBOW','and','are','different.']\n","test_vector = make_context_vector(test_data, word_to_index)\n","result = model(test_vector)\n","print('Prediction : ', index_to_word[torch.argmax(result[0]).item()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUC1ShRjhB9b","executionInfo":{"status":"ok","timestamp":1748681195516,"user_tz":-540,"elapsed":4362,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"c96e16ae-2e4e-4369-d9ce-17cbc5508a20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch =  0 , loss =  tensor(295.8551, grad_fn=<AddBackward0>)\n","epoch =  1 , loss =  tensor(287.8702, grad_fn=<AddBackward0>)\n","epoch =  2 , loss =  tensor(280.3029, grad_fn=<AddBackward0>)\n","epoch =  3 , loss =  tensor(273.0851, grad_fn=<AddBackward0>)\n","epoch =  4 , loss =  tensor(265.9677, grad_fn=<AddBackward0>)\n","epoch =  5 , loss =  tensor(258.9339, grad_fn=<AddBackward0>)\n","epoch =  6 , loss =  tensor(251.9113, grad_fn=<AddBackward0>)\n","epoch =  7 , loss =  tensor(244.9059, grad_fn=<AddBackward0>)\n","epoch =  8 , loss =  tensor(237.9139, grad_fn=<AddBackward0>)\n","epoch =  9 , loss =  tensor(230.8799, grad_fn=<AddBackward0>)\n","epoch =  10 , loss =  tensor(223.7068, grad_fn=<AddBackward0>)\n","epoch =  11 , loss =  tensor(216.4106, grad_fn=<AddBackward0>)\n","epoch =  12 , loss =  tensor(208.9970, grad_fn=<AddBackward0>)\n","epoch =  13 , loss =  tensor(201.5432, grad_fn=<AddBackward0>)\n","epoch =  14 , loss =  tensor(194.0235, grad_fn=<AddBackward0>)\n","epoch =  15 , loss =  tensor(186.5363, grad_fn=<AddBackward0>)\n","epoch =  16 , loss =  tensor(179.1320, grad_fn=<AddBackward0>)\n","epoch =  17 , loss =  tensor(171.8006, grad_fn=<AddBackward0>)\n","epoch =  18 , loss =  tensor(164.6281, grad_fn=<AddBackward0>)\n","epoch =  19 , loss =  tensor(157.6286, grad_fn=<AddBackward0>)\n","epoch =  20 , loss =  tensor(150.8179, grad_fn=<AddBackward0>)\n","epoch =  21 , loss =  tensor(144.2027, grad_fn=<AddBackward0>)\n","epoch =  22 , loss =  tensor(137.7669, grad_fn=<AddBackward0>)\n","epoch =  23 , loss =  tensor(131.5224, grad_fn=<AddBackward0>)\n","epoch =  24 , loss =  tensor(125.4533, grad_fn=<AddBackward0>)\n","epoch =  25 , loss =  tensor(119.5510, grad_fn=<AddBackward0>)\n","epoch =  26 , loss =  tensor(113.8239, grad_fn=<AddBackward0>)\n","epoch =  27 , loss =  tensor(108.2942, grad_fn=<AddBackward0>)\n","epoch =  28 , loss =  tensor(102.9434, grad_fn=<AddBackward0>)\n","epoch =  29 , loss =  tensor(97.7644, grad_fn=<AddBackward0>)\n","epoch =  30 , loss =  tensor(92.7404, grad_fn=<AddBackward0>)\n","epoch =  31 , loss =  tensor(87.8971, grad_fn=<AddBackward0>)\n","epoch =  32 , loss =  tensor(83.2348, grad_fn=<AddBackward0>)\n","epoch =  33 , loss =  tensor(78.7379, grad_fn=<AddBackward0>)\n","epoch =  34 , loss =  tensor(74.4484, grad_fn=<AddBackward0>)\n","epoch =  35 , loss =  tensor(70.3330, grad_fn=<AddBackward0>)\n","epoch =  36 , loss =  tensor(66.3915, grad_fn=<AddBackward0>)\n","epoch =  37 , loss =  tensor(62.6408, grad_fn=<AddBackward0>)\n","epoch =  38 , loss =  tensor(59.0858, grad_fn=<AddBackward0>)\n","epoch =  39 , loss =  tensor(55.7217, grad_fn=<AddBackward0>)\n","epoch =  40 , loss =  tensor(52.5325, grad_fn=<AddBackward0>)\n","epoch =  41 , loss =  tensor(49.5191, grad_fn=<AddBackward0>)\n","epoch =  42 , loss =  tensor(46.6848, grad_fn=<AddBackward0>)\n","epoch =  43 , loss =  tensor(44.0195, grad_fn=<AddBackward0>)\n","epoch =  44 , loss =  tensor(41.5395, grad_fn=<AddBackward0>)\n","epoch =  45 , loss =  tensor(39.2280, grad_fn=<AddBackward0>)\n","epoch =  46 , loss =  tensor(37.0637, grad_fn=<AddBackward0>)\n","epoch =  47 , loss =  tensor(35.0527, grad_fn=<AddBackward0>)\n","epoch =  48 , loss =  tensor(33.1803, grad_fn=<AddBackward0>)\n","epoch =  49 , loss =  tensor(31.4418, grad_fn=<AddBackward0>)\n","epoch =  50 , loss =  tensor(29.8226, grad_fn=<AddBackward0>)\n","epoch =  51 , loss =  tensor(28.3207, grad_fn=<AddBackward0>)\n","epoch =  52 , loss =  tensor(26.9232, grad_fn=<AddBackward0>)\n","epoch =  53 , loss =  tensor(25.6283, grad_fn=<AddBackward0>)\n","epoch =  54 , loss =  tensor(24.4239, grad_fn=<AddBackward0>)\n","epoch =  55 , loss =  tensor(23.2994, grad_fn=<AddBackward0>)\n","epoch =  56 , loss =  tensor(22.2551, grad_fn=<AddBackward0>)\n","epoch =  57 , loss =  tensor(21.2847, grad_fn=<AddBackward0>)\n","epoch =  58 , loss =  tensor(20.3769, grad_fn=<AddBackward0>)\n","epoch =  59 , loss =  tensor(19.5314, grad_fn=<AddBackward0>)\n","epoch =  60 , loss =  tensor(18.7394, grad_fn=<AddBackward0>)\n","epoch =  61 , loss =  tensor(17.9987, grad_fn=<AddBackward0>)\n","epoch =  62 , loss =  tensor(17.3061, grad_fn=<AddBackward0>)\n","epoch =  63 , loss =  tensor(16.6570, grad_fn=<AddBackward0>)\n","epoch =  64 , loss =  tensor(16.0488, grad_fn=<AddBackward0>)\n","epoch =  65 , loss =  tensor(15.4745, grad_fn=<AddBackward0>)\n","epoch =  66 , loss =  tensor(14.9359, grad_fn=<AddBackward0>)\n","epoch =  67 , loss =  tensor(14.4259, grad_fn=<AddBackward0>)\n","epoch =  68 , loss =  tensor(13.9472, grad_fn=<AddBackward0>)\n","epoch =  69 , loss =  tensor(13.4953, grad_fn=<AddBackward0>)\n","epoch =  70 , loss =  tensor(13.0666, grad_fn=<AddBackward0>)\n","epoch =  71 , loss =  tensor(12.6598, grad_fn=<AddBackward0>)\n","epoch =  72 , loss =  tensor(12.2771, grad_fn=<AddBackward0>)\n","epoch =  73 , loss =  tensor(11.9124, grad_fn=<AddBackward0>)\n","epoch =  74 , loss =  tensor(11.5663, grad_fn=<AddBackward0>)\n","epoch =  75 , loss =  tensor(11.2382, grad_fn=<AddBackward0>)\n","epoch =  76 , loss =  tensor(10.9248, grad_fn=<AddBackward0>)\n","epoch =  77 , loss =  tensor(10.6264, grad_fn=<AddBackward0>)\n","epoch =  78 , loss =  tensor(10.3414, grad_fn=<AddBackward0>)\n","epoch =  79 , loss =  tensor(10.0703, grad_fn=<AddBackward0>)\n","epoch =  80 , loss =  tensor(9.8108, grad_fn=<AddBackward0>)\n","epoch =  81 , loss =  tensor(9.5627, grad_fn=<AddBackward0>)\n","epoch =  82 , loss =  tensor(9.3263, grad_fn=<AddBackward0>)\n","epoch =  83 , loss =  tensor(9.0992, grad_fn=<AddBackward0>)\n","epoch =  84 , loss =  tensor(8.8825, grad_fn=<AddBackward0>)\n","epoch =  85 , loss =  tensor(8.6742, grad_fn=<AddBackward0>)\n","epoch =  86 , loss =  tensor(8.4752, grad_fn=<AddBackward0>)\n","epoch =  87 , loss =  tensor(8.2835, grad_fn=<AddBackward0>)\n","epoch =  88 , loss =  tensor(8.1000, grad_fn=<AddBackward0>)\n","epoch =  89 , loss =  tensor(7.9233, grad_fn=<AddBackward0>)\n","epoch =  90 , loss =  tensor(7.7538, grad_fn=<AddBackward0>)\n","epoch =  91 , loss =  tensor(7.5897, grad_fn=<AddBackward0>)\n","epoch =  92 , loss =  tensor(7.4321, grad_fn=<AddBackward0>)\n","epoch =  93 , loss =  tensor(7.2806, grad_fn=<AddBackward0>)\n","epoch =  94 , loss =  tensor(7.1341, grad_fn=<AddBackward0>)\n","epoch =  95 , loss =  tensor(6.9924, grad_fn=<AddBackward0>)\n","epoch =  96 , loss =  tensor(6.8560, grad_fn=<AddBackward0>)\n","epoch =  97 , loss =  tensor(6.7246, grad_fn=<AddBackward0>)\n","epoch =  98 , loss =  tensor(6.5971, grad_fn=<AddBackward0>)\n","epoch =  99 , loss =  tensor(6.4741, grad_fn=<AddBackward0>)\n","Prediction :  Skip-Gram\n"]}]},{"cell_type":"markdown","source":["# Skip-Gram\n","#### Skip-Gram은 한 단어를 제외한 모든 단어를 제거하고 한 단어를 통해 문맥에서 주변 단어를 예측하여 학습합니다.따라서 벡터를 입력으로 사용하여 여러 개의 출력 벡터를 생성합니다.CBOW와 Skip-Gram은 서로 다릅니다."],"metadata":{"id":"jUvDX5R9inXr"}},{"cell_type":"code","source":["## using pytorch\n","import torch\n","import torch.nn as nn\n","\n","EMBEDDING_DIM = 128\n","EPOCHS = 200\n","CONTEXT_SIZE = 4\n","\n","example_sentence = \"\"\"In the case of CBOW, one word is eliminated, and the word is predicted from surrounding words.\n","Therefore, it takes multiple input vectors as inputs to the model and creates one output vector.\n","In contrast, Skip-Gram learns by removing all words except one word and predicting the surrounding words in the context through one word.\n","So, it takes a vector as input and produces multiple output vectors.\n","CBOW and Skip-Gram are different.\"\"\".split()\n","\n","# convert context to index vector\n","def make_context_vector(context, word_to_ix):\n","  idxs = word_to_ix[context]\n","  return torch.tensor(idxs, dtype=torch.long)\n","\n","# make dataset function\n","def make_data(sentence):\n","  data = []\n","  for i in range(2, len(example_sentence) - 2):\n","    context = example_sentence[i]\n","    target = [example_sentence[i - 2], example_sentence[i - 1], example_sentence[i + 1], example_sentence[i + 2]]\n","    data.append((context, target))\n","  return data\n","\n","#(1) 입력받은 문장을 단어로 쪼개고, 중복을 제거해줍니다.\n","vocab = set(example_sentence)\n","vocab_size = len(example_sentence)\n","\n","#(2) 단어 : 인덱스, 인덱스 : 단어를 가지는 딕셔너리를 선언해 줍니다.\n","word_to_index = {word:index for index, word in enumerate(vocab)}\n","index_to_word = {index:word for index, word in enumerate(vocab)}\n","\n","#(3) 학습을 위한 데이터를 생성해 줍니다.\n","data = make_data(example_sentence)\n","\n","#(4) Skip-Gram 모델을 정의해 줍니다.\n","class SKIP_GRAM(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, context_size):\n","    super(SKIP_GRAM, self).__init__()\n","    self.context_size = context_size\n","    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","    self.layer1 = nn.Linear(embedding_dim, 64)\n","    self.activation1 = nn.ReLU()\n","\n","    self.layer2 = nn.Linear(64, vocab_size * context_size)\n","    self.activation2 = nn.LogSoftmax(dim = -1)\n","\n","  def forward(self, inputs):\n","    embeded_vector = self.embeddings(inputs)\n","    output = self.activation1(self.layer1(embeded_vector))\n","    output = self.activation2(self.layer2(output))\n","    return output.view(self.context_size,vocab_size)\n","\n","#(5) 모델을 선언해주고, loss function, optimizer등을 선언해줍니다.\n","model = SKIP_GRAM(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n","loss_function = nn.NLLLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","\n","#(6) 학습을 진행합니다.\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    for context, target in data:\n","        context_vector = make_context_vector(context, word_to_index)\n","        log_probs = model(context_vector)\n","        total_loss += loss_function(log_probs, torch.tensor([word_to_index[t] for t in target]))\n","    print('epoch = ',epoch, ', loss = ',total_loss)\n","    optimizer.zero_grad()\n","    total_loss.backward()\n","    optimizer.step()\n","\n","#(7) test하고 싶은 문장을 뽑고, test를 진행합니다.\n","test_data = 'Skip-Gram'\n","test_vector = make_context_vector(test_data, word_to_index)\n","result = model(test_vector)\n","print('Prediction : ', [index_to_word[torch.argmax(r).item()] for r in result])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sm2InHTUiYXo","executionInfo":{"status":"ok","timestamp":1748681594929,"user_tz":-540,"elapsed":8036,"user":{"displayName":"유진철","userId":"18428759730043573350"}},"outputId":"818aa985-1585-41c7-af30-49133e0e9973"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch =  0 , loss =  tensor(388.0920, grad_fn=<AddBackward0>)\n","epoch =  1 , loss =  tensor(387.5418, grad_fn=<AddBackward0>)\n","epoch =  2 , loss =  tensor(386.9979, grad_fn=<AddBackward0>)\n","epoch =  3 , loss =  tensor(386.4577, grad_fn=<AddBackward0>)\n","epoch =  4 , loss =  tensor(385.9203, grad_fn=<AddBackward0>)\n","epoch =  5 , loss =  tensor(385.3864, grad_fn=<AddBackward0>)\n","epoch =  6 , loss =  tensor(384.8557, grad_fn=<AddBackward0>)\n","epoch =  7 , loss =  tensor(384.3317, grad_fn=<AddBackward0>)\n","epoch =  8 , loss =  tensor(383.8112, grad_fn=<AddBackward0>)\n","epoch =  9 , loss =  tensor(383.2948, grad_fn=<AddBackward0>)\n","epoch =  10 , loss =  tensor(382.7795, grad_fn=<AddBackward0>)\n","epoch =  11 , loss =  tensor(382.2679, grad_fn=<AddBackward0>)\n","epoch =  12 , loss =  tensor(381.7593, grad_fn=<AddBackward0>)\n","epoch =  13 , loss =  tensor(381.2530, grad_fn=<AddBackward0>)\n","epoch =  14 , loss =  tensor(380.7502, grad_fn=<AddBackward0>)\n","epoch =  15 , loss =  tensor(380.2521, grad_fn=<AddBackward0>)\n","epoch =  16 , loss =  tensor(379.7583, grad_fn=<AddBackward0>)\n","epoch =  17 , loss =  tensor(379.2644, grad_fn=<AddBackward0>)\n","epoch =  18 , loss =  tensor(378.7715, grad_fn=<AddBackward0>)\n","epoch =  19 , loss =  tensor(378.2793, grad_fn=<AddBackward0>)\n","epoch =  20 , loss =  tensor(377.7874, grad_fn=<AddBackward0>)\n","epoch =  21 , loss =  tensor(377.2968, grad_fn=<AddBackward0>)\n","epoch =  22 , loss =  tensor(376.8087, grad_fn=<AddBackward0>)\n","epoch =  23 , loss =  tensor(376.3217, grad_fn=<AddBackward0>)\n","epoch =  24 , loss =  tensor(375.8361, grad_fn=<AddBackward0>)\n","epoch =  25 , loss =  tensor(375.3528, grad_fn=<AddBackward0>)\n","epoch =  26 , loss =  tensor(374.8680, grad_fn=<AddBackward0>)\n","epoch =  27 , loss =  tensor(374.3830, grad_fn=<AddBackward0>)\n","epoch =  28 , loss =  tensor(373.8997, grad_fn=<AddBackward0>)\n","epoch =  29 , loss =  tensor(373.4190, grad_fn=<AddBackward0>)\n","epoch =  30 , loss =  tensor(372.9370, grad_fn=<AddBackward0>)\n","epoch =  31 , loss =  tensor(372.4561, grad_fn=<AddBackward0>)\n","epoch =  32 , loss =  tensor(371.9778, grad_fn=<AddBackward0>)\n","epoch =  33 , loss =  tensor(371.4984, grad_fn=<AddBackward0>)\n","epoch =  34 , loss =  tensor(371.0179, grad_fn=<AddBackward0>)\n","epoch =  35 , loss =  tensor(370.5375, grad_fn=<AddBackward0>)\n","epoch =  36 , loss =  tensor(370.0564, grad_fn=<AddBackward0>)\n","epoch =  37 , loss =  tensor(369.5744, grad_fn=<AddBackward0>)\n","epoch =  38 , loss =  tensor(369.0903, grad_fn=<AddBackward0>)\n","epoch =  39 , loss =  tensor(368.6037, grad_fn=<AddBackward0>)\n","epoch =  40 , loss =  tensor(368.1141, grad_fn=<AddBackward0>)\n","epoch =  41 , loss =  tensor(367.6219, grad_fn=<AddBackward0>)\n","epoch =  42 , loss =  tensor(367.1288, grad_fn=<AddBackward0>)\n","epoch =  43 , loss =  tensor(366.6334, grad_fn=<AddBackward0>)\n","epoch =  44 , loss =  tensor(366.1373, grad_fn=<AddBackward0>)\n","epoch =  45 , loss =  tensor(365.6374, grad_fn=<AddBackward0>)\n","epoch =  46 , loss =  tensor(365.1351, grad_fn=<AddBackward0>)\n","epoch =  47 , loss =  tensor(364.6290, grad_fn=<AddBackward0>)\n","epoch =  48 , loss =  tensor(364.1192, grad_fn=<AddBackward0>)\n","epoch =  49 , loss =  tensor(363.6072, grad_fn=<AddBackward0>)\n","epoch =  50 , loss =  tensor(363.0918, grad_fn=<AddBackward0>)\n","epoch =  51 , loss =  tensor(362.5695, grad_fn=<AddBackward0>)\n","epoch =  52 , loss =  tensor(362.0453, grad_fn=<AddBackward0>)\n","epoch =  53 , loss =  tensor(361.5170, grad_fn=<AddBackward0>)\n","epoch =  54 , loss =  tensor(360.9850, grad_fn=<AddBackward0>)\n","epoch =  55 , loss =  tensor(360.4481, grad_fn=<AddBackward0>)\n","epoch =  56 , loss =  tensor(359.9092, grad_fn=<AddBackward0>)\n","epoch =  57 , loss =  tensor(359.3660, grad_fn=<AddBackward0>)\n","epoch =  58 , loss =  tensor(358.8174, grad_fn=<AddBackward0>)\n","epoch =  59 , loss =  tensor(358.2652, grad_fn=<AddBackward0>)\n","epoch =  60 , loss =  tensor(357.7082, grad_fn=<AddBackward0>)\n","epoch =  61 , loss =  tensor(357.1465, grad_fn=<AddBackward0>)\n","epoch =  62 , loss =  tensor(356.5807, grad_fn=<AddBackward0>)\n","epoch =  63 , loss =  tensor(356.0108, grad_fn=<AddBackward0>)\n","epoch =  64 , loss =  tensor(355.4368, grad_fn=<AddBackward0>)\n","epoch =  65 , loss =  tensor(354.8572, grad_fn=<AddBackward0>)\n","epoch =  66 , loss =  tensor(354.2711, grad_fn=<AddBackward0>)\n","epoch =  67 , loss =  tensor(353.6801, grad_fn=<AddBackward0>)\n","epoch =  68 , loss =  tensor(353.0861, grad_fn=<AddBackward0>)\n","epoch =  69 , loss =  tensor(352.4868, grad_fn=<AddBackward0>)\n","epoch =  70 , loss =  tensor(351.8833, grad_fn=<AddBackward0>)\n","epoch =  71 , loss =  tensor(351.2751, grad_fn=<AddBackward0>)\n","epoch =  72 , loss =  tensor(350.6619, grad_fn=<AddBackward0>)\n","epoch =  73 , loss =  tensor(350.0430, grad_fn=<AddBackward0>)\n","epoch =  74 , loss =  tensor(349.4181, grad_fn=<AddBackward0>)\n","epoch =  75 , loss =  tensor(348.7877, grad_fn=<AddBackward0>)\n","epoch =  76 , loss =  tensor(348.1495, grad_fn=<AddBackward0>)\n","epoch =  77 , loss =  tensor(347.5033, grad_fn=<AddBackward0>)\n","epoch =  78 , loss =  tensor(346.8516, grad_fn=<AddBackward0>)\n","epoch =  79 , loss =  tensor(346.1933, grad_fn=<AddBackward0>)\n","epoch =  80 , loss =  tensor(345.5285, grad_fn=<AddBackward0>)\n","epoch =  81 , loss =  tensor(344.8573, grad_fn=<AddBackward0>)\n","epoch =  82 , loss =  tensor(344.1806, grad_fn=<AddBackward0>)\n","epoch =  83 , loss =  tensor(343.4979, grad_fn=<AddBackward0>)\n","epoch =  84 , loss =  tensor(342.8092, grad_fn=<AddBackward0>)\n","epoch =  85 , loss =  tensor(342.1150, grad_fn=<AddBackward0>)\n","epoch =  86 , loss =  tensor(341.4148, grad_fn=<AddBackward0>)\n","epoch =  87 , loss =  tensor(340.7082, grad_fn=<AddBackward0>)\n","epoch =  88 , loss =  tensor(339.9952, grad_fn=<AddBackward0>)\n","epoch =  89 , loss =  tensor(339.2758, grad_fn=<AddBackward0>)\n","epoch =  90 , loss =  tensor(338.5510, grad_fn=<AddBackward0>)\n","epoch =  91 , loss =  tensor(337.8171, grad_fn=<AddBackward0>)\n","epoch =  92 , loss =  tensor(337.0778, grad_fn=<AddBackward0>)\n","epoch =  93 , loss =  tensor(336.3322, grad_fn=<AddBackward0>)\n","epoch =  94 , loss =  tensor(335.5789, grad_fn=<AddBackward0>)\n","epoch =  95 , loss =  tensor(334.8214, grad_fn=<AddBackward0>)\n","epoch =  96 , loss =  tensor(334.0570, grad_fn=<AddBackward0>)\n","epoch =  97 , loss =  tensor(333.2868, grad_fn=<AddBackward0>)\n","epoch =  98 , loss =  tensor(332.5113, grad_fn=<AddBackward0>)\n","epoch =  99 , loss =  tensor(331.7283, grad_fn=<AddBackward0>)\n","epoch =  100 , loss =  tensor(330.9402, grad_fn=<AddBackward0>)\n","epoch =  101 , loss =  tensor(330.1454, grad_fn=<AddBackward0>)\n","epoch =  102 , loss =  tensor(329.3448, grad_fn=<AddBackward0>)\n","epoch =  103 , loss =  tensor(328.5385, grad_fn=<AddBackward0>)\n","epoch =  104 , loss =  tensor(327.7265, grad_fn=<AddBackward0>)\n","epoch =  105 , loss =  tensor(326.9094, grad_fn=<AddBackward0>)\n","epoch =  106 , loss =  tensor(326.0869, grad_fn=<AddBackward0>)\n","epoch =  107 , loss =  tensor(325.2578, grad_fn=<AddBackward0>)\n","epoch =  108 , loss =  tensor(324.4221, grad_fn=<AddBackward0>)\n","epoch =  109 , loss =  tensor(323.5805, grad_fn=<AddBackward0>)\n","epoch =  110 , loss =  tensor(322.7334, grad_fn=<AddBackward0>)\n","epoch =  111 , loss =  tensor(321.8802, grad_fn=<AddBackward0>)\n","epoch =  112 , loss =  tensor(321.0211, grad_fn=<AddBackward0>)\n","epoch =  113 , loss =  tensor(320.1559, grad_fn=<AddBackward0>)\n","epoch =  114 , loss =  tensor(319.2880, grad_fn=<AddBackward0>)\n","epoch =  115 , loss =  tensor(318.4119, grad_fn=<AddBackward0>)\n","epoch =  116 , loss =  tensor(317.5317, grad_fn=<AddBackward0>)\n","epoch =  117 , loss =  tensor(316.6458, grad_fn=<AddBackward0>)\n","epoch =  118 , loss =  tensor(315.7533, grad_fn=<AddBackward0>)\n","epoch =  119 , loss =  tensor(314.8565, grad_fn=<AddBackward0>)\n","epoch =  120 , loss =  tensor(313.9543, grad_fn=<AddBackward0>)\n","epoch =  121 , loss =  tensor(313.0466, grad_fn=<AddBackward0>)\n","epoch =  122 , loss =  tensor(312.1341, grad_fn=<AddBackward0>)\n","epoch =  123 , loss =  tensor(311.2176, grad_fn=<AddBackward0>)\n","epoch =  124 , loss =  tensor(310.2966, grad_fn=<AddBackward0>)\n","epoch =  125 , loss =  tensor(309.3707, grad_fn=<AddBackward0>)\n","epoch =  126 , loss =  tensor(308.4401, grad_fn=<AddBackward0>)\n","epoch =  127 , loss =  tensor(307.5067, grad_fn=<AddBackward0>)\n","epoch =  128 , loss =  tensor(306.5683, grad_fn=<AddBackward0>)\n","epoch =  129 , loss =  tensor(305.6262, grad_fn=<AddBackward0>)\n","epoch =  130 , loss =  tensor(304.6802, grad_fn=<AddBackward0>)\n","epoch =  131 , loss =  tensor(303.7295, grad_fn=<AddBackward0>)\n","epoch =  132 , loss =  tensor(302.7739, grad_fn=<AddBackward0>)\n","epoch =  133 , loss =  tensor(301.8152, grad_fn=<AddBackward0>)\n","epoch =  134 , loss =  tensor(300.8516, grad_fn=<AddBackward0>)\n","epoch =  135 , loss =  tensor(299.8873, grad_fn=<AddBackward0>)\n","epoch =  136 , loss =  tensor(298.9189, grad_fn=<AddBackward0>)\n","epoch =  137 , loss =  tensor(297.9459, grad_fn=<AddBackward0>)\n","epoch =  138 , loss =  tensor(296.9725, grad_fn=<AddBackward0>)\n","epoch =  139 , loss =  tensor(295.9960, grad_fn=<AddBackward0>)\n","epoch =  140 , loss =  tensor(295.0164, grad_fn=<AddBackward0>)\n","epoch =  141 , loss =  tensor(294.0331, grad_fn=<AddBackward0>)\n","epoch =  142 , loss =  tensor(293.0478, grad_fn=<AddBackward0>)\n","epoch =  143 , loss =  tensor(292.0607, grad_fn=<AddBackward0>)\n","epoch =  144 , loss =  tensor(291.0725, grad_fn=<AddBackward0>)\n","epoch =  145 , loss =  tensor(290.0814, grad_fn=<AddBackward0>)\n","epoch =  146 , loss =  tensor(289.0906, grad_fn=<AddBackward0>)\n","epoch =  147 , loss =  tensor(288.0974, grad_fn=<AddBackward0>)\n","epoch =  148 , loss =  tensor(287.1034, grad_fn=<AddBackward0>)\n","epoch =  149 , loss =  tensor(286.1091, grad_fn=<AddBackward0>)\n","epoch =  150 , loss =  tensor(285.1095, grad_fn=<AddBackward0>)\n","epoch =  151 , loss =  tensor(284.1095, grad_fn=<AddBackward0>)\n","epoch =  152 , loss =  tensor(283.1099, grad_fn=<AddBackward0>)\n","epoch =  153 , loss =  tensor(282.1077, grad_fn=<AddBackward0>)\n","epoch =  154 , loss =  tensor(281.1063, grad_fn=<AddBackward0>)\n","epoch =  155 , loss =  tensor(280.1022, grad_fn=<AddBackward0>)\n","epoch =  156 , loss =  tensor(279.0986, grad_fn=<AddBackward0>)\n","epoch =  157 , loss =  tensor(278.0951, grad_fn=<AddBackward0>)\n","epoch =  158 , loss =  tensor(277.0909, grad_fn=<AddBackward0>)\n","epoch =  159 , loss =  tensor(276.0868, grad_fn=<AddBackward0>)\n","epoch =  160 , loss =  tensor(275.0818, grad_fn=<AddBackward0>)\n","epoch =  161 , loss =  tensor(274.0763, grad_fn=<AddBackward0>)\n","epoch =  162 , loss =  tensor(273.0701, grad_fn=<AddBackward0>)\n","epoch =  163 , loss =  tensor(272.0654, grad_fn=<AddBackward0>)\n","epoch =  164 , loss =  tensor(271.0596, grad_fn=<AddBackward0>)\n","epoch =  165 , loss =  tensor(270.0529, grad_fn=<AddBackward0>)\n","epoch =  166 , loss =  tensor(269.0457, grad_fn=<AddBackward0>)\n","epoch =  167 , loss =  tensor(268.0396, grad_fn=<AddBackward0>)\n","epoch =  168 , loss =  tensor(267.0355, grad_fn=<AddBackward0>)\n","epoch =  169 , loss =  tensor(266.0294, grad_fn=<AddBackward0>)\n","epoch =  170 , loss =  tensor(265.0266, grad_fn=<AddBackward0>)\n","epoch =  171 , loss =  tensor(264.0227, grad_fn=<AddBackward0>)\n","epoch =  172 , loss =  tensor(263.0209, grad_fn=<AddBackward0>)\n","epoch =  173 , loss =  tensor(262.0199, grad_fn=<AddBackward0>)\n","epoch =  174 , loss =  tensor(261.0196, grad_fn=<AddBackward0>)\n","epoch =  175 , loss =  tensor(260.0197, grad_fn=<AddBackward0>)\n","epoch =  176 , loss =  tensor(259.0218, grad_fn=<AddBackward0>)\n","epoch =  177 , loss =  tensor(258.0257, grad_fn=<AddBackward0>)\n","epoch =  178 , loss =  tensor(257.0309, grad_fn=<AddBackward0>)\n","epoch =  179 , loss =  tensor(256.0375, grad_fn=<AddBackward0>)\n","epoch =  180 , loss =  tensor(255.0447, grad_fn=<AddBackward0>)\n","epoch =  181 , loss =  tensor(254.0547, grad_fn=<AddBackward0>)\n","epoch =  182 , loss =  tensor(253.0653, grad_fn=<AddBackward0>)\n","epoch =  183 , loss =  tensor(252.0790, grad_fn=<AddBackward0>)\n","epoch =  184 , loss =  tensor(251.0919, grad_fn=<AddBackward0>)\n","epoch =  185 , loss =  tensor(250.1116, grad_fn=<AddBackward0>)\n","epoch =  186 , loss =  tensor(249.1286, grad_fn=<AddBackward0>)\n","epoch =  187 , loss =  tensor(248.1496, grad_fn=<AddBackward0>)\n","epoch =  188 , loss =  tensor(247.1716, grad_fn=<AddBackward0>)\n","epoch =  189 , loss =  tensor(246.1972, grad_fn=<AddBackward0>)\n","epoch =  190 , loss =  tensor(245.2245, grad_fn=<AddBackward0>)\n","epoch =  191 , loss =  tensor(244.2546, grad_fn=<AddBackward0>)\n","epoch =  192 , loss =  tensor(243.2864, grad_fn=<AddBackward0>)\n","epoch =  193 , loss =  tensor(242.3213, grad_fn=<AddBackward0>)\n","epoch =  194 , loss =  tensor(241.3596, grad_fn=<AddBackward0>)\n","epoch =  195 , loss =  tensor(240.3988, grad_fn=<AddBackward0>)\n","epoch =  196 , loss =  tensor(239.4419, grad_fn=<AddBackward0>)\n","epoch =  197 , loss =  tensor(238.4882, grad_fn=<AddBackward0>)\n","epoch =  198 , loss =  tensor(237.5370, grad_fn=<AddBackward0>)\n","epoch =  199 , loss =  tensor(236.5893, grad_fn=<AddBackward0>)\n","Prediction :  ['In', 'and', 'are', 'different.']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_fKe1_ocicRi"},"execution_count":null,"outputs":[]}]}